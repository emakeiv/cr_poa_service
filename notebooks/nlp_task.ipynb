{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "      TensorDataset, \n",
    "      DataLoader,\n",
    "      Dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_lt = spacy.load(\"lt_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://admin:admin@localhost/rc_poa_main_db')\n",
    "session = sessionmaker(bind=engine)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.dal.repo.registry import RepositoryRegistry\n",
    "from app.dal.repo.impl import PowerOfAttorneyDocumentSampleRepository\n",
    "from app.dal.repo.impl import OtherDocumentSampleRepository\n",
    "\n",
    "repository_registry = RepositoryRegistry(session)\n",
    "repository_registry.add('other_doc_sample_repo', OtherDocumentSampleRepository)\n",
    "repository_registry.add('poa_doc_sample_repo', PowerOfAttorneyDocumentSampleRepository)\n",
    "\n",
    "other_doc_sample_repo = repository_registry.get('other_doc_sample_repo')\n",
    "poa_doc_sample_repo = repository_registry.get('poa_doc_sample_repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_docs = other_doc_sample_repo.list()\n",
    "poa_docs = poa_doc_sample_repo.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(poa_docs))\n",
    "print(len(other_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower().replace('\\n', ' ')\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "def remove_stopwords_and_lemmatize(text):\n",
    "    doc = nlp_lt(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text.strip() != \"\"]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def debug_preprocessing(text, nlp_pipeline=nlp_lt):\n",
    "    if debug: \n",
    "        print(\"original text:\", text)\n",
    "    normalized_text = normalize_text(text)\n",
    "    if debug: \n",
    "        print(\"normalized text:\", normalized_text)\n",
    "\n",
    "    doc = nlp_pipeline(normalized_text)\n",
    "    for token in doc:\n",
    "        if debug:\n",
    "            print(f\"Token: {token.text}, Lemma: {token.lemma_}, Stop word: {token.is_stop}\")\n",
    "\n",
    "    processed_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n",
    "    if debug:\n",
    "        print(\"processed text:\", processed_text)\n",
    "\n",
    "    return processed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_documents(docs, label):\n",
    "    X, y = [], []\n",
    "    for doc in docs:\n",
    "        text_content = doc['document_content'] \n",
    "        processed_text = normalize_text(text_content)\n",
    "        processed_text = remove_stopwords_and_lemmatize(processed_text)\n",
    "        X.append(processed_text)\n",
    "        y.append(label)\n",
    "    return X, y\n",
    "\n",
    "X_other, y_other = preprocess_documents(other_docs, 0)  \n",
    "X_poa, y_poa = preprocess_documents(poa_docs, 1)\n",
    "\n",
    "X = X_other + X_poa\n",
    "y = y_other + y_poa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# first split into training and temporary dataset\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# splitting the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "31\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vector(text):\n",
    "    \"\"\"\n",
    "    returns a vector representation of text by averaging word vectors.\n",
    "    \"\"\"\n",
    "    doc = nlp_lt(text)\n",
    "    vectors = [word.vector for word in doc if word.has_vector]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # If no words with vectors, return zero vector\n",
    "        return np.zeros((nlp_lt.vocab.vectors_length,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32471/4219376970.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /root/pytorch/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  X_train_tensor = torch.tensor(X_train_vec, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_train_vec = [get_document_vector(doc) for doc in X_train]\n",
    "X_test_vec = [get_document_vector(doc) for doc in X_test]\n",
    "X_val_vec = [get_document_vector(doc) for doc in X_val]\n",
    "\n",
    "# converting to pytorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_vec, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_vec, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_vec, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# create pytorch datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# create data loaders\n",
    "batch_size = 32  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Document Vector Shape: (300,)\n",
      "Single Document Vector: [-0.06430432  0.27475923 -0.3541736  -0.10364912 -0.32291234  1.010614\n",
      " -0.09030529 -0.3150915  -0.70823944  0.31533512 -0.15625282 -0.38854504\n",
      " -0.12503    -0.14096925  0.51507473 -1.3231012   0.31076294 -0.10594788\n",
      " -0.16917428 -1.659768    0.40807486 -0.6739119  -1.0235971  -1.5363826\n",
      "  0.5161458  -0.61891884  0.3732429   0.07661914 -0.63867366 -1.5677009\n",
      "  0.21594073 -0.08779796  1.2092576   0.9365319  -0.21614724 -0.67505544\n",
      "  0.63504344  0.39531597  0.16833295 -0.9037188   0.8214453   0.03703367\n",
      " -0.5721789   0.07333278  0.8431701  -0.76942396 -0.4706811  -0.7790541\n",
      " -0.35626405  0.19593754  0.32616955  1.0265838  -0.7420928   0.18463543\n",
      "  0.3566031  -0.8873718   0.43770012  0.5939207   0.31821996 -0.5019004\n",
      "  0.6614856   0.21741381  0.42934683 -0.49532443 -0.08457708 -0.44355625\n",
      " -0.41820368 -0.15816379  0.6026082  -0.49290517 -0.00749871 -0.7328573\n",
      "  0.29493982  0.9066127   1.0079615  -0.51098996  0.62100744  0.262111\n",
      " -0.72863203  0.31486195  0.27042204 -1.0703559   0.69973296  0.7323558\n",
      " -0.02598306  0.5186548  -0.17751938  0.00524058 -0.68949205 -0.04868842\n",
      " -0.89164925 -0.39778817  0.54970133  1.5368497   0.85071254  0.13977301\n",
      "  0.34222     0.2758792   0.7009331   0.63376033  1.1651614  -0.20437922\n",
      " -0.298797    0.1642473   0.31312737  0.82287115  0.36257172 -1.0070279\n",
      "  1.0324901   0.16347176  0.94418657  0.02052984  0.8375433   0.26891667\n",
      "  0.03631272  0.07983164  0.05544331 -1.3939936  -0.19325078  0.88661385\n",
      "  0.3084771   0.7115159   0.208278    0.88091207 -0.11390483 -0.19973843\n",
      " -0.6932162   1.2053691  -0.42299995  0.32270095  1.1156749  -0.5192488\n",
      " -0.90693426  0.5675974  -0.06670328  0.13411674 -0.30295783  0.1916883\n",
      "  0.6000146   0.19263011 -0.1239616   0.02829498 -0.32024145  0.12342979\n",
      " -0.04150563 -0.70998985  1.3415588   1.5335386  -0.30039358  0.3822785\n",
      " -0.18588142  0.32858157  1.4497304  -0.7040867  -0.6619042  -0.8914899\n",
      " -0.05694181 -0.22226433 -0.05825058 -0.72944546 -0.871119   -1.1879038\n",
      " -1.0314536  -0.5186922  -0.25078437 -0.50772196 -0.6219268  -1.2909565\n",
      "  0.1516983   0.08457106  0.02302946  0.27167088 -0.43573198 -0.61979604\n",
      " -0.52737     0.55129117  0.05689372 -1.0658164  -1.5436227   0.46583292\n",
      "  0.06049998 -0.32287303  0.16167216 -1.1789175   0.04009579 -0.2478749\n",
      "  0.12056546 -0.2182677   0.12798631 -1.6684092  -0.810035   -0.7071756\n",
      " -0.65230966  1.5386677  -0.22295451  0.08016217  0.21253394  0.7709181\n",
      " -0.6959712  -0.5852931   0.4845148  -0.32397512  0.7909215  -0.00843057\n",
      "  0.10731393 -0.58606505 -0.27424577  0.29277036 -0.01556916  0.23664057\n",
      " -1.0467592   0.4420576  -1.1240172  -0.06796092 -0.35008532 -0.10745189\n",
      " -0.11562199  0.26322687  0.57191384 -0.8436064  -0.85287166 -0.06806374\n",
      " -0.3281649  -0.53924465  1.1208603   0.5529193  -0.54105103  0.25972587\n",
      "  0.12547435  0.35819086  1.1251384  -0.05894882 -0.69390565  1.8986835\n",
      "  0.5404226  -1.1874967   0.01162173 -1.5528842   0.9644862  -1.2648828\n",
      "  0.0955922   0.924845   -0.14511691  0.14554681  0.25688985 -0.6292873\n",
      "  0.4586697  -0.8759437  -0.42696926  0.15689144  1.4968845   0.35975856\n",
      " -0.3213414  -0.23285788  1.1802117  -1.0514137   1.4665247  -0.31027663\n",
      "  0.35865882 -0.26382467 -0.33122766  0.35639796  0.4634395   0.01851827\n",
      "  0.10337479 -0.24091184 -0.8280676  -0.6827238  -0.05252314 -0.17731836\n",
      " -0.83883166 -0.24275391 -0.25326675 -0.30548397 -0.36905986 -0.01549499\n",
      "  1.5574331  -0.6427193   1.1233175   0.36042204 -0.26285812 -0.34542492\n",
      " -0.26381898  1.7502391  -0.2535245   0.8827671  -0.19468948  0.09470668\n",
      " -0.25447267 -0.75498074  0.33988324  0.6809072  -0.12111124  0.27123758\n",
      " -0.20368046 -0.38189054 -0.15668638 -0.22960755 -0.01360082 -1.8334371 ]\n"
     ]
    }
   ],
   "source": [
    "# testing get_document_vector\n",
    "\n",
    "sample_doc = X_train[0]\n",
    "doc_vector = get_document_vector(sample_doc)\n",
    "\n",
    "# Print the shape and the vector\n",
    "print(\"Single Document Vector Shape:\", doc_vector.shape)\n",
    "print(\"Single Document Vector:\", doc_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x sample input size:  torch.Size([32, 300])\n",
      "x sample input shape:  torch.Size([32, 300])\n",
      "y sample input size:  torch.Size([32])\n",
      "y sample input shape:  torch.Size([32])\n",
      "Sample input: \n",
      " tensor([[-1.5807e-01,  9.4809e-02, -4.9957e-01,  ..., -1.8160e-01,\n",
      "         -1.3103e-01, -1.2076e+00],\n",
      "        [ 8.6286e-02,  4.0666e-01, -3.4649e-01,  ..., -1.0089e+00,\n",
      "          1.1389e-01, -1.5971e+00],\n",
      "        [-2.9467e-01,  1.9163e-02, -4.7624e-01,  ..., -5.2729e-02,\n",
      "         -1.9784e-01, -1.7354e+00],\n",
      "        ...,\n",
      "        [-6.5167e-01,  1.1841e+00, -1.0935e+00,  ...,  1.5753e-03,\n",
      "          5.4216e-01,  1.4524e+00],\n",
      "        [-2.2419e-01,  1.9267e-01, -6.9894e-01,  ...,  3.5441e-02,\n",
      "          2.1323e-01,  1.6696e-01],\n",
      "        [-3.5893e-01,  4.2068e-01, -3.0535e-01,  ..., -9.6494e-02,\n",
      "         -2.1197e-01, -1.5021e+00]])\n",
      "Sample output: \n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    " \n",
    "print('x sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('x sample input shape: ', sample_x.shape) \n",
    "\n",
    "print('y sample input size: ', sample_y.size()) # batch_size, seq_length\n",
    "print('y sample input shape: ', sample_y.shape)\n",
    "\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample output: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X Shape:  torch.Size([32, 300])\n",
      "Batch Y Shape:  torch.Size([32])\n",
      "Sample Batch X: \n",
      " tensor([[-0.1581, -0.0938, -0.7563,  ..., -0.2085, -0.1345, -0.1724],\n",
      "        [ 0.7513,  1.7450,  0.1361,  ..., -0.7466,  0.8366,  0.3584],\n",
      "        [-0.1387,  0.6129, -0.6653,  ..., -0.6531, -0.1631, -1.7425],\n",
      "        ...,\n",
      "        [-0.0153,  0.5699, -0.6358,  ..., -0.2727, -0.0056, -0.9716],\n",
      "        [-0.0884,  0.4620, -0.3475,  ..., -0.3745, -0.2780, -1.7463],\n",
      "        [-0.1581,  0.0948, -0.4996,  ..., -0.1816, -0.1310, -1.2076]])\n",
      "Sample Batch Y: \n",
      " tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader test\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "# Print the shapes and sample data\n",
    "print('Batch X Shape: ', sample_x.shape) # Expected: [batch_size, seq_len, embedding_dim]\n",
    "print('Batch Y Shape: ', sample_y.shape) # Expected: [batch_size]\n",
    "print('Sample Batch X: \\n', sample_x)\n",
    "print('Sample Batch Y: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POA_RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 no_layers, \n",
    "                 hidden_dim, \n",
    "                 embedding_dim, \n",
    "                 output_dim=1, \n",
    "                 drop_prob=0.5,\n",
    "                 debug=False):\n",
    "        super(POA_RNN, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.no_layers = no_layers\n",
    "        self.debug = debug\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=no_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout=drop_prob if no_layers > 1 else 0)\n",
    "\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # debugging: Print the shapes of input and hidden state\n",
    "        # should be [batch_size, seq_len, embedding_dim]\n",
    "        if debug:\n",
    "            print(f\"Input shape: {x.shape}\")  \n",
    "            # should be [num_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        x = x.unsqueeze(1) \n",
    "        if debug:\n",
    "            print(f\"shape after embedding: {x.shape}\")\n",
    "            print(f\"hidden state shape: {hidden[0].shape}, {hidden[1].shape}\")\n",
    "        # LSTM output\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Reshape output to (batch_size*seq_length, hidden_dim)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # Sigmoid function\n",
    "        sig_out = torch.sigmoid(out)\n",
    "        \n",
    "        # Reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]  # get last batch of labels\n",
    "        \n",
    "        # Return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''Initializes hidden state'''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "\n",
    "        weight = next(self.parameters()).data\n",
    "        h0 = weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        c0 = weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        \n",
    "        # Debugging: Print the shapes of hidden states\n",
    "        if debug:\n",
    "            print(f\"h0 shape: {h0.shape}\")\n",
    "            print(f\"c0 shape: {c0.shape}\")\n",
    "\n",
    "        return (h0, c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "embedding_dim = nlp_lt.vocab.vectors_length\n",
    "print(embedding_dim)\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "drop_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POA_RNN(\n",
       "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = POA_RNN(\n",
    "      no_layers, \n",
    "      hidden_dim, \n",
    "      embedding_dim, \n",
    "      output_dim, \n",
    "      drop_prob\n",
    "      )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input shape: torch.Size([32, 300])\n",
      "hidden input shape: torch.Size([2, 32, 256]), torch.Size([2, 32, 256])\n"
     ]
    }
   ],
   "source": [
    "# assuming each word vector is of length 300\n",
    "embedding_dim = 300\n",
    "seq_len = 300  # length of the sequence of word vectors\n",
    "sample_batch_size = 32  \n",
    "\n",
    "# creating a sample input tensor with random embeddings (replace with actual word vectors in practice)\n",
    "sample_input = torch.randn(sample_batch_size, embedding_dim)\n",
    "sample_input = sample_input.to(device)\n",
    "\n",
    "# Initialize hidden state\n",
    "hidden = model.init_hidden(sample_batch_size)\n",
    "# Forward pass (this should not raise an error if everything is correct)\n",
    "print(f\"sample_input shape: {sample_input.shape}\")\n",
    "print(f\"hidden input shape: {hidden[0].shape}, {hidden[1].shape}\") \n",
    "output, new_hidden = model(sample_input, hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    " \n",
    "def accuracy(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "      filename='training_log.txt', \n",
    "      level=logging.INFO, \n",
    "      format='%(asctime)s %(levelname)s: %(message)s', \n",
    "      datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 1/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0004702225836808793 val_loss : 0.06476309895515442\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 2/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00048439083238918104 val_loss : 0.06318439543247223\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 3/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00045257761421453325 val_loss : 0.06184075027704239\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 4/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0005328426976120681 val_loss : 0.06023450568318367\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 5/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002842920439434238 val_loss : 0.059575531631708145\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 6/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0005132721220434177 val_loss : 0.05841153487563133\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 7/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0003540585426890175 val_loss : 0.05728922039270401\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 8/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0005054300512711052 val_loss : 0.056065883487463\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 9/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0008805551920886501 val_loss : 0.055119823664426804\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 10/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0007122864682969521 val_loss : 0.054083045572042465\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 11/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00030157796140883875 val_loss : 0.05354258418083191\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 12/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00023638969632884256 val_loss : 0.05334152653813362\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 13/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0004572041033497953 val_loss : 0.05312708765268326\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 14/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0006072863621739089 val_loss : 0.05280124023556709\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 15/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0004277312710655679 val_loss : 0.05158066004514694\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 16/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00018829648006430945 val_loss : 0.05045319348573685\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 17/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0004711398826657387 val_loss : 0.0493566133081913\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 18/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00022667949269816745 val_loss : 0.048416782170534134\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 19/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002822873311743024 val_loss : 0.0475647933781147\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 20/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0003061424937641277 val_loss : 0.04644925147294998\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 21/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002825741887136246 val_loss : 0.04537375643849373\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 22/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00027811223844764754 val_loss : 0.044368743896484375\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 23/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00020988391397622764 val_loss : 0.04356491565704346\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 24/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0003017127972270828 val_loss : 0.04297864809632301\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 25/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00020386437190609286 val_loss : 0.042647622525691986\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 26/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001620264050870901 val_loss : 0.0423550084233284\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 27/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002543632844208332 val_loss : 0.0420515201985836\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 28/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002898494352393755 val_loss : 0.04143112152814865\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 29/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00017423815261281562 val_loss : 0.04120287299156189\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 30/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001949868976680591 val_loss : 0.04080898314714432\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 31/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00020479556169448188 val_loss : 0.04048449918627739\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 32/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0003281634861195926 val_loss : 0.03988057002425194\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 33/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002878666639844596 val_loss : 0.03947712853550911\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 34/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002487589894371922 val_loss : 0.038784418255090714\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 35/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0003003870222528349 val_loss : 0.03806169703602791\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 36/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00014584742275474126 val_loss : 0.03767894208431244\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 37/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012144974734837888 val_loss : 0.03756894916296005\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 38/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00034665617363316414 val_loss : 0.037648048251867294\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 39/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00029663999566764687 val_loss : 0.03752858191728592\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 40/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001901965272736561 val_loss : 0.03765132278203964\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 41/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00025157862005471544 val_loss : 0.03772638365626335\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 42/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00019441666809143497 val_loss : 0.038037776947021484\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 43/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002700047107282444 val_loss : 0.03921739012002945\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 44/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00013489527755154994 val_loss : 0.03977835178375244\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 45/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012363794226075698 val_loss : 0.03998098149895668\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 46/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00016365937485716132 val_loss : 0.040336694568395615\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 47/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001071268683517701 val_loss : 0.04071151837706566\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 48/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001254663388863264 val_loss : 0.040812522172927856\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 49/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012821722693843186 val_loss : 0.04072492942214012\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 50/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00011213578713977767 val_loss : 0.04065275192260742\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 51/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012865302337559115 val_loss : 0.04038793593645096\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 52/1000\n",
      "Steps: 0\n",
      "train_loss : 9.040507566169254e-05 val_loss : 0.040074422955513\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 53/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00014560809704562417 val_loss : 0.0398620143532753\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 54/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00017520772980788023 val_loss : 0.039945147931575775\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 55/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00019466248058961356 val_loss : 0.040038906037807465\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 56/1000\n",
      "Steps: 0\n",
      "train_loss : 8.444127743132413e-05 val_loss : 0.039949141442775726\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 57/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00011653872370516183 val_loss : 0.03987501561641693\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 58/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002453986516684381 val_loss : 0.04019181802868843\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 59/1000\n",
      "Steps: 0\n",
      "train_loss : 8.204942187148845e-05 val_loss : 0.04048654064536095\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 60/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0003861899568619265 val_loss : 0.04042717441916466\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 61/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00018073906867357436 val_loss : 0.04048796743154526\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 62/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002511646024458969 val_loss : 0.04061512276530266\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 63/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00015506495697081846 val_loss : 0.04074980691075325\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 64/1000\n",
      "Steps: 0\n",
      "train_loss : 8.624111933386303e-05 val_loss : 0.04065093770623207\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 65/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001404970439580211 val_loss : 0.04061880335211754\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 66/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00011764007804231369 val_loss : 0.040409404784440994\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 67/1000\n",
      "Steps: 0\n",
      "train_loss : 5.0305895274505016e-05 val_loss : 0.04025254771113396\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 68/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00022729424485987693 val_loss : 0.04017070308327675\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 69/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0002130964292518911 val_loss : 0.04057278484106064\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 70/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00010737101802078541 val_loss : 0.04190274327993393\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 71/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001248987091003073 val_loss : 0.05162663385272026\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 72/1000\n",
      "Steps: 0\n",
      "train_loss : 0.000186787218626705 val_loss : 0.06228801980614662\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 73/1000\n",
      "Steps: 0\n",
      "train_loss : 0.000149438368725896 val_loss : 0.06864582747220993\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 74/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00011333009588270216 val_loss : 0.07195057719945908\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 75/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012785977867224574 val_loss : 0.07353762537240982\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 76/1000\n",
      "Steps: 0\n",
      "train_loss : 6.460587032961485e-05 val_loss : 0.07337459921836853\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 77/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001803368099444924 val_loss : 0.07262000441551208\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 78/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012038598715662374 val_loss : 0.0722251757979393\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 79/1000\n",
      "Steps: 0\n",
      "train_loss : 7.652731819689507e-05 val_loss : 0.07223338633775711\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 80/1000\n",
      "Steps: 0\n",
      "train_loss : 6.828799860159052e-05 val_loss : 0.07257547229528427\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 81/1000\n",
      "Steps: 0\n",
      "train_loss : 0.0001379844317852985 val_loss : 0.07365013659000397\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 82/1000\n",
      "Steps: 0\n",
      "train_loss : 7.317198283089965e-05 val_loss : 0.07409504801034927\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 83/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00031387686790367296 val_loss : 0.07439963519573212\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 84/1000\n",
      "Steps: 0\n",
      "train_loss : 5.131778043505619e-05 val_loss : 0.07387788593769073\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 85/1000\n",
      "Steps: 0\n",
      "train_loss : 4.075596789334668e-05 val_loss : 0.07361464202404022\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 86/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00010038324276138156 val_loss : 0.07338883727788925\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 87/1000\n",
      "Steps: 0\n",
      "train_loss : 8.758976764511317e-05 val_loss : 0.07287007570266724\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 88/1000\n",
      "Steps: 0\n",
      "train_loss : 8.786447074271564e-05 val_loss : 0.07235141843557358\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 89/1000\n",
      "Steps: 0\n",
      "train_loss : 8.504549559802399e-05 val_loss : 0.07122142612934113\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 90/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00010225205799088143 val_loss : 0.07040970027446747\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 91/1000\n",
      "Steps: 0\n",
      "train_loss : 8.75633620808003e-05 val_loss : 0.06992806494235992\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 92/1000\n",
      "Steps: 0\n",
      "train_loss : 5.8151122721028516e-05 val_loss : 0.06902813911437988\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 93/1000\n",
      "Steps: 0\n",
      "train_loss : 9.139966865632232e-05 val_loss : 0.06832262873649597\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 94/1000\n",
      "Steps: 0\n",
      "train_loss : 6.160508712582669e-05 val_loss : 0.06772249191999435\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 95/1000\n",
      "Steps: 0\n",
      "train_loss : 8.861416367835772e-05 val_loss : 0.06753641366958618\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 96/1000\n",
      "Steps: 0\n",
      "train_loss : 7.469201630101452e-05 val_loss : 0.06729073077440262\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 97/1000\n",
      "Steps: 0\n",
      "train_loss : 5.8076128470929686e-05 val_loss : 0.06718133389949799\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 98/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00014603693589378963 val_loss : 0.06661953777074814\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 99/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00027874880356648646 val_loss : 0.06594809889793396\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 100/1000\n",
      "Steps: 0\n",
      "train_loss : 8.69967516109682e-05 val_loss : 0.06474152207374573\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 101/1000\n",
      "Steps: 0\n",
      "train_loss : 3.632092816587829e-05 val_loss : 0.06388057768344879\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 102/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00017322945235491715 val_loss : 0.06286776065826416\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 103/1000\n",
      "Steps: 0\n",
      "train_loss : 5.58438764528546e-05 val_loss : 0.06213953718543053\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 104/1000\n",
      "Steps: 0\n",
      "train_loss : 5.1208201603003546e-05 val_loss : 0.06157418340444565\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 105/1000\n",
      "Steps: 0\n",
      "train_loss : 5.9222486652288356e-05 val_loss : 0.06155446916818619\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 106/1000\n",
      "Steps: 0\n",
      "train_loss : 3.103229848875344e-05 val_loss : 0.061438094824552536\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 107/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00013097989894959028 val_loss : 0.06130813807249069\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 108/1000\n",
      "Steps: 0\n",
      "train_loss : 4.64202704051786e-05 val_loss : 0.060918956995010376\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 109/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6081270263821355e-05 val_loss : 0.06065469607710838\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 110/1000\n",
      "Steps: 0\n",
      "train_loss : 6.220836969532684e-05 val_loss : 0.06043913587927818\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 111/1000\n",
      "Steps: 0\n",
      "train_loss : 5.011063549318351e-05 val_loss : 0.06004568189382553\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 112/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00011928490330319619 val_loss : 0.05965692177414894\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 113/1000\n",
      "Steps: 0\n",
      "train_loss : 4.554781432943855e-05 val_loss : 0.05908545106649399\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 114/1000\n",
      "Steps: 0\n",
      "train_loss : 3.8176799625944115e-05 val_loss : 0.05864328518509865\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 115/1000\n",
      "Steps: 0\n",
      "train_loss : 4.261576086719288e-05 val_loss : 0.058324433863162994\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 116/1000\n",
      "Steps: 0\n",
      "train_loss : 4.587215466926864e-05 val_loss : 0.058278050273656845\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 117/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00010741813516688126 val_loss : 0.05676056072115898\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 118/1000\n",
      "Steps: 0\n",
      "train_loss : 5.621516893370426e-05 val_loss : 0.055609870702028275\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 119/1000\n",
      "Steps: 0\n",
      "train_loss : 1.284002057673206e-05 val_loss : 0.05491861328482628\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 120/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00012426361031430132 val_loss : 0.05434958636760712\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 121/1000\n",
      "Steps: 0\n",
      "train_loss : 5.427897890513123e-05 val_loss : 0.05355144664645195\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 122/1000\n",
      "Steps: 0\n",
      "train_loss : 2.895861960041657e-05 val_loss : 0.052871380001306534\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 123/1000\n",
      "Steps: 0\n",
      "train_loss : 6.992573551087844e-05 val_loss : 0.052535392343997955\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 124/1000\n",
      "Steps: 0\n",
      "train_loss : 4.7382378511429124e-05 val_loss : 0.05221625044941902\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 125/1000\n",
      "Steps: 0\n",
      "train_loss : 6.169335200070236e-05 val_loss : 0.052042171359062195\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 126/1000\n",
      "Steps: 0\n",
      "train_loss : 4.948076823438896e-05 val_loss : 0.05204247310757637\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 127/1000\n",
      "Steps: 0\n",
      "train_loss : 6.965951447455155e-05 val_loss : 0.05207644775509834\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 128/1000\n",
      "Steps: 0\n",
      "train_loss : 6.463483765628553e-05 val_loss : 0.051960915327072144\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 129/1000\n",
      "Steps: 0\n",
      "train_loss : 7.081869430294318e-05 val_loss : 0.05184376612305641\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 130/1000\n",
      "Steps: 0\n",
      "train_loss : 4.1855096043263984e-05 val_loss : 0.05188227444887161\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 131/1000\n",
      "Steps: 0\n",
      "train_loss : 6.982476304528973e-05 val_loss : 0.0521678701043129\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 132/1000\n",
      "Steps: 0\n",
      "train_loss : 3.419093600314227e-05 val_loss : 0.05199688300490379\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 133/1000\n",
      "Steps: 0\n",
      "train_loss : 2.386633027526841e-05 val_loss : 0.05190363898873329\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 134/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6270755574842043e-05 val_loss : 0.05197498947381973\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 135/1000\n",
      "Steps: 0\n",
      "train_loss : 6.335731354738528e-05 val_loss : 0.05201234668493271\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 136/1000\n",
      "Steps: 0\n",
      "train_loss : 2.244148597583262e-05 val_loss : 0.051934655755758286\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 137/1000\n",
      "Steps: 0\n",
      "train_loss : 4.398662449602853e-05 val_loss : 0.052321020513772964\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 138/1000\n",
      "Steps: 0\n",
      "train_loss : 6.362738806728885e-05 val_loss : 0.0532565638422966\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 139/1000\n",
      "Steps: 0\n",
      "train_loss : 2.590110217397523e-05 val_loss : 0.05412350594997406\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 140/1000\n",
      "Steps: 0\n",
      "train_loss : 4.666914417157386e-05 val_loss : 0.05457529425621033\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 141/1000\n",
      "Steps: 0\n",
      "train_loss : 6.068134098313749e-05 val_loss : 0.05495611950755119\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 142/1000\n",
      "Steps: 0\n",
      "train_loss : 6.886041082907469e-05 val_loss : 0.05533146113157272\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 143/1000\n",
      "Steps: 0\n",
      "train_loss : 5.599772883897458e-05 val_loss : 0.05561843141913414\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 144/1000\n",
      "Steps: 0\n",
      "train_loss : 3.493985068416805e-05 val_loss : 0.05569455772638321\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 145/1000\n",
      "Steps: 0\n",
      "train_loss : 6.555545464834723e-05 val_loss : 0.055586013942956924\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 146/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4684581879009784e-05 val_loss : 0.05544040724635124\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 147/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2905150171936838e-05 val_loss : 0.055321913212537766\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 148/1000\n",
      "Steps: 0\n",
      "train_loss : 3.0307495671877403e-05 val_loss : 0.05522482842206955\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 149/1000\n",
      "Steps: 0\n",
      "train_loss : 4.8064810800951816e-05 val_loss : 0.05528680235147476\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 150/1000\n",
      "Steps: 0\n",
      "train_loss : 8.665620629244586e-05 val_loss : 0.055264901369810104\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 151/1000\n",
      "Steps: 0\n",
      "train_loss : 1.716208480502246e-05 val_loss : 0.05513198673725128\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 152/1000\n",
      "Steps: 0\n",
      "train_loss : 4.166301621353341e-05 val_loss : 0.05562390014529228\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 153/1000\n",
      "Steps: 0\n",
      "train_loss : 2.526831735849555e-05 val_loss : 0.05593177676200867\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 154/1000\n",
      "Steps: 0\n",
      "train_loss : 2.075055899695144e-05 val_loss : 0.056047357618808746\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 155/1000\n",
      "Steps: 0\n",
      "train_loss : 2.513487979740603e-05 val_loss : 0.05614110827445984\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 156/1000\n",
      "Steps: 0\n",
      "train_loss : 4.423550669798715e-05 val_loss : 0.05616132915019989\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 157/1000\n",
      "Steps: 0\n",
      "train_loss : 4.791425624262047e-05 val_loss : 0.056260064244270325\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 158/1000\n",
      "Steps: 0\n",
      "train_loss : 6.792719741497422e-05 val_loss : 0.056226830929517746\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 159/1000\n",
      "Steps: 0\n",
      "train_loss : 3.169324312466415e-05 val_loss : 0.055988460779190063\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 160/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9751201693907206e-05 val_loss : 0.055749159306287766\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 161/1000\n",
      "Steps: 0\n",
      "train_loss : 5.37564540081803e-05 val_loss : 0.055460527539253235\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 162/1000\n",
      "Steps: 0\n",
      "train_loss : 2.796427023099568e-05 val_loss : 0.05517103150486946\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 163/1000\n",
      "Steps: 0\n",
      "train_loss : 3.216539453205769e-05 val_loss : 0.05666016414761543\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 164/1000\n",
      "Steps: 0\n",
      "train_loss : 3.1778264201420825e-05 val_loss : 0.05744605511426926\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 165/1000\n",
      "Steps: 0\n",
      "train_loss : 4.571139234030852e-05 val_loss : 0.05783741548657417\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 166/1000\n",
      "Steps: 0\n",
      "train_loss : 5.9958706833640464e-05 val_loss : 0.057916875928640366\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 167/1000\n",
      "Steps: 0\n",
      "train_loss : 1.848518147653522e-05 val_loss : 0.05778556689620018\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 168/1000\n",
      "Steps: 0\n",
      "train_loss : 0.00010926672529194547 val_loss : 0.05757984519004822\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 169/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1768497324737837e-05 val_loss : 0.05710641294717789\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 170/1000\n",
      "Steps: 0\n",
      "train_loss : 6.43759617332762e-05 val_loss : 0.05652372166514397\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 171/1000\n",
      "Steps: 0\n",
      "train_loss : 3.761269231290498e-05 val_loss : 0.05591501668095589\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 172/1000\n",
      "Steps: 0\n",
      "train_loss : 3.736332151902388e-05 val_loss : 0.05563376471400261\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 173/1000\n",
      "Steps: 0\n",
      "train_loss : 3.057925917460125e-05 val_loss : 0.05530381575226784\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 174/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3777533726843103e-05 val_loss : 0.05509297922253609\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 175/1000\n",
      "Steps: 0\n",
      "train_loss : 4.9378040762348975e-05 val_loss : 0.054817214608192444\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 176/1000\n",
      "Steps: 0\n",
      "train_loss : 2.7257960414317495e-05 val_loss : 0.05450126901268959\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 177/1000\n",
      "Steps: 0\n",
      "train_loss : 4.6500629434831356e-05 val_loss : 0.05406281352043152\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 178/1000\n",
      "Steps: 0\n",
      "train_loss : 2.013489000773916e-05 val_loss : 0.05364006385207176\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 179/1000\n",
      "Steps: 0\n",
      "train_loss : 2.875786689173765e-05 val_loss : 0.053344037383794785\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 180/1000\n",
      "Steps: 0\n",
      "train_loss : 1.657546204114624e-05 val_loss : 0.053072232753038406\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 181/1000\n",
      "Steps: 0\n",
      "train_loss : 1.266432998363598e-05 val_loss : 0.05267981067299843\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 182/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4708969285948114e-05 val_loss : 0.05207224562764168\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 183/1000\n",
      "Steps: 0\n",
      "train_loss : 6.633401575300013e-05 val_loss : 0.05156394839286804\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 184/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8073557271236496e-05 val_loss : 0.05128784105181694\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 185/1000\n",
      "Steps: 0\n",
      "train_loss : 1.830190574310109e-05 val_loss : 0.05114421620965004\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 186/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4646369481852162e-05 val_loss : 0.05109246075153351\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 187/1000\n",
      "Steps: 0\n",
      "train_loss : 2.577779436023775e-05 val_loss : 0.051099393516778946\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 188/1000\n",
      "Steps: 0\n",
      "train_loss : 3.68279069334676e-05 val_loss : 0.051201462745666504\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 189/1000\n",
      "Steps: 0\n",
      "train_loss : 3.1274099410438796e-05 val_loss : 0.051089316606521606\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 190/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1945466460238095e-05 val_loss : 0.05090309679508209\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 191/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3352986340796632e-05 val_loss : 0.05082647502422333\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 192/1000\n",
      "Steps: 0\n",
      "train_loss : 7.472135644093214e-06 val_loss : 0.05076732113957405\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 193/1000\n",
      "Steps: 0\n",
      "train_loss : 1.658880347008562e-05 val_loss : 0.0513744056224823\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 194/1000\n",
      "Steps: 0\n",
      "train_loss : 3.192789288277709e-05 val_loss : 0.05208520218729973\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 195/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0540137259340554e-05 val_loss : 0.05249687284231186\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 196/1000\n",
      "Steps: 0\n",
      "train_loss : 3.806688616805332e-05 val_loss : 0.05288019776344299\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 197/1000\n",
      "Steps: 0\n",
      "train_loss : 2.153726350115903e-05 val_loss : 0.053245626389980316\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 198/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7259290257243264e-05 val_loss : 0.05352671071887016\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 199/1000\n",
      "Steps: 0\n",
      "train_loss : 3.28111279713994e-05 val_loss : 0.053895074874162674\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 200/1000\n",
      "Steps: 0\n",
      "train_loss : 3.1269919395526814e-05 val_loss : 0.05412987619638443\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 201/1000\n",
      "Steps: 0\n",
      "train_loss : 3.1231149523591736e-05 val_loss : 0.05395747348666191\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 202/1000\n",
      "Steps: 0\n",
      "train_loss : 1.569287530855945e-05 val_loss : 0.0539042167365551\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 203/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5130382093484515e-05 val_loss : 0.06208640709519386\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 204/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6085418653565284e-05 val_loss : 0.0669020339846611\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 205/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0609247104630413e-05 val_loss : 0.06973723322153091\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 206/1000\n",
      "Steps: 0\n",
      "train_loss : 3.159323231329836e-05 val_loss : 0.07146618515253067\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 207/1000\n",
      "Steps: 0\n",
      "train_loss : 8.140474346873816e-05 val_loss : 0.07221977412700653\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 208/1000\n",
      "Steps: 0\n",
      "train_loss : 3.938704080610478e-05 val_loss : 0.07217688858509064\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 209/1000\n",
      "Steps: 0\n",
      "train_loss : 3.769111987139695e-05 val_loss : 0.07223496586084366\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 210/1000\n",
      "Steps: 0\n",
      "train_loss : 4.012627214819986e-05 val_loss : 0.07199572026729584\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 211/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1396391943208074e-05 val_loss : 0.07178809493780136\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 212/1000\n",
      "Steps: 0\n",
      "train_loss : 3.0521664280058757e-05 val_loss : 0.0714540183544159\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 213/1000\n",
      "Steps: 0\n",
      "train_loss : 3.466398717364427e-05 val_loss : 0.07102369517087936\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 214/1000\n",
      "Steps: 0\n",
      "train_loss : 4.289597025035619e-05 val_loss : 0.07057886570692062\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 215/1000\n",
      "Steps: 0\n",
      "train_loss : 8.053371233245344e-05 val_loss : 0.07008753716945648\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 216/1000\n",
      "Steps: 0\n",
      "train_loss : 7.762282672274523e-06 val_loss : 0.07002001255750656\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 217/1000\n",
      "Steps: 0\n",
      "train_loss : 1.047283758452977e-05 val_loss : 0.07018440216779709\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 218/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6884407532179466e-05 val_loss : 0.07030642777681351\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 219/1000\n",
      "Steps: 0\n",
      "train_loss : 3.139740403526048e-05 val_loss : 0.07043730467557907\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 220/1000\n",
      "Steps: 0\n",
      "train_loss : 2.185093910611613e-05 val_loss : 0.07039923965930939\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 221/1000\n",
      "Steps: 0\n",
      "train_loss : 3.396054892164102e-05 val_loss : 0.07007721811532974\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 222/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8074613874196074e-05 val_loss : 0.06970544159412384\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 223/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5740614583137357e-05 val_loss : 0.06938617676496506\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 224/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3404668925431906e-05 val_loss : 0.06917595118284225\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 225/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6823738789971684e-05 val_loss : 0.06870995461940765\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 226/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0437524485951144e-05 val_loss : 0.06839598715305328\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 227/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2423488826461834e-05 val_loss : 0.06847566366195679\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 228/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0952403633600625e-05 val_loss : 0.06884291768074036\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 229/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3917019236941996e-05 val_loss : 0.06914495676755905\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 230/1000\n",
      "Steps: 0\n",
      "train_loss : 7.25248510207166e-06 val_loss : 0.06929774582386017\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 231/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9122236949442595e-05 val_loss : 0.06972317397594452\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 232/1000\n",
      "Steps: 0\n",
      "train_loss : 3.7743747702734255e-05 val_loss : 0.0780394896864891\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 233/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8230825978425856e-05 val_loss : 0.08297297358512878\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 234/1000\n",
      "Steps: 0\n",
      "train_loss : 6.89000981992649e-06 val_loss : 0.085613913834095\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 235/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3705273920550098e-05 val_loss : 0.08713596314191818\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 236/1000\n",
      "Steps: 0\n",
      "train_loss : 1.448354018975806e-05 val_loss : 0.08858443796634674\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 237/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9611235211414167e-05 val_loss : 0.08944940567016602\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 238/1000\n",
      "Steps: 0\n",
      "train_loss : 3.235821970406505e-05 val_loss : 0.08967845886945724\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 239/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6747541366157748e-05 val_loss : 0.08970692753791809\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 240/1000\n",
      "Steps: 0\n",
      "train_loss : 4.8950591849461486e-05 val_loss : 0.0896807312965393\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 241/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2006671374820143e-05 val_loss : 0.08932524174451828\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 242/1000\n",
      "Steps: 0\n",
      "train_loss : 9.51920058014366e-06 val_loss : 0.08909396082162857\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 243/1000\n",
      "Steps: 0\n",
      "train_loss : 4.570065596567474e-05 val_loss : 0.08865828812122345\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 244/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1736061753708783e-05 val_loss : 0.08830369263887405\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 245/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4030447493951214e-05 val_loss : 0.08797553181648254\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 246/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0578874844213715e-05 val_loss : 0.08756432682275772\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 247/1000\n",
      "Steps: 0\n",
      "train_loss : 2.026933289016597e-05 val_loss : 0.09115395694971085\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 248/1000\n",
      "Steps: 0\n",
      "train_loss : 8.09198173783443e-06 val_loss : 0.09388962388038635\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 249/1000\n",
      "Steps: 0\n",
      "train_loss : 7.0436904934467744e-06 val_loss : 0.09549856185913086\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 250/1000\n",
      "Steps: 0\n",
      "train_loss : 1.921668124396092e-05 val_loss : 0.09637174010276794\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 251/1000\n",
      "Steps: 0\n",
      "train_loss : 3.3154742675378655e-05 val_loss : 0.0967792421579361\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 252/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6811616007526025e-05 val_loss : 0.09646201878786087\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 253/1000\n",
      "Steps: 0\n",
      "train_loss : 8.087758908459364e-06 val_loss : 0.0963556244969368\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 254/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8005472747972816e-05 val_loss : 0.09622982889413834\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 255/1000\n",
      "Steps: 0\n",
      "train_loss : 8.112085720313188e-06 val_loss : 0.09604321420192719\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 256/1000\n",
      "Steps: 0\n",
      "train_loss : 9.892848163417512e-06 val_loss : 0.09575288742780685\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 257/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8269750976051e-05 val_loss : 0.09553441405296326\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 258/1000\n",
      "Steps: 0\n",
      "train_loss : 6.576599582786003e-06 val_loss : 0.09543148428201675\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 259/1000\n",
      "Steps: 0\n",
      "train_loss : 2.305793599362005e-05 val_loss : 0.09539151936769485\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 260/1000\n",
      "Steps: 0\n",
      "train_loss : 9.734950572237721e-06 val_loss : 0.09516191482543945\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 261/1000\n",
      "Steps: 0\n",
      "train_loss : 2.9624744956890937e-05 val_loss : 0.0947548970580101\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 262/1000\n",
      "Steps: 0\n",
      "train_loss : 8.505991348783937e-06 val_loss : 0.09443719685077667\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 263/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0504118731423658e-05 val_loss : 0.09411238133907318\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 264/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3031027535580505e-05 val_loss : 0.09365006536245346\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 265/1000\n",
      "Steps: 0\n",
      "train_loss : 6.975737051106989e-06 val_loss : 0.09311862289905548\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 266/1000\n",
      "Steps: 0\n",
      "train_loss : 4.128356536057254e-05 val_loss : 0.09236578643321991\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 267/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6715363398134286e-05 val_loss : 0.09110670536756516\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 268/1000\n",
      "Steps: 0\n",
      "train_loss : 1.313709488499626e-05 val_loss : 0.09027304500341415\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 269/1000\n",
      "Steps: 0\n",
      "train_loss : 3.51607981201596e-05 val_loss : 0.08967599272727966\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 270/1000\n",
      "Steps: 0\n",
      "train_loss : 8.333543996741355e-06 val_loss : 0.08885760605335236\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 271/1000\n",
      "Steps: 0\n",
      "train_loss : 8.039935727310876e-06 val_loss : 0.08815111964941025\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 272/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6107367662243634e-05 val_loss : 0.08761699497699738\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 273/1000\n",
      "Steps: 0\n",
      "train_loss : 8.878484300112177e-06 val_loss : 0.0872316062450409\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 274/1000\n",
      "Steps: 0\n",
      "train_loss : 2.659817705534806e-05 val_loss : 0.08685453236103058\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 275/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5834141706582158e-05 val_loss : 0.0865594819188118\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 276/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7019256824823968e-05 val_loss : 0.08637379109859467\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 277/1000\n",
      "Steps: 0\n",
      "train_loss : 4.531684419362137e-06 val_loss : 0.08648501336574554\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 278/1000\n",
      "Steps: 0\n",
      "train_loss : 3.444816752562474e-06 val_loss : 0.086842380464077\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 279/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0271688427110349e-05 val_loss : 0.08699355274438858\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 280/1000\n",
      "Steps: 0\n",
      "train_loss : 3.8290236545890366e-05 val_loss : 0.08683084696531296\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 281/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2558788458582058e-05 val_loss : 0.08659724146127701\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 282/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6663234009683948e-05 val_loss : 0.08632027357816696\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 283/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4977441276187165e-05 val_loss : 0.08604918420314789\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 284/1000\n",
      "Steps: 0\n",
      "train_loss : 6.382367519108811e-06 val_loss : 0.0858975499868393\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 285/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3954618668776676e-05 val_loss : 0.08566833287477493\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 286/1000\n",
      "Steps: 0\n",
      "train_loss : 6.04589855015547e-06 val_loss : 0.08551794290542603\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 287/1000\n",
      "Steps: 0\n",
      "train_loss : 5.533786059004342e-05 val_loss : 0.08519906550645828\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 288/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2158383251280613e-05 val_loss : 0.08520086109638214\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 289/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1447865608715801e-05 val_loss : 0.08589260280132294\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 290/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0439326285904826e-05 val_loss : 0.0862414762377739\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 291/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6181798980596795e-05 val_loss : 0.08622635900974274\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 292/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4134184817748974e-05 val_loss : 0.08589092642068863\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 293/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1080651177053369e-05 val_loss : 0.08542323857545853\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 294/1000\n",
      "Steps: 0\n",
      "train_loss : 4.803762806204759e-06 val_loss : 0.08520663529634476\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 295/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1215927543162252e-05 val_loss : 0.08537562936544418\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 296/1000\n",
      "Steps: 0\n",
      "train_loss : 1.309550015662353e-05 val_loss : 0.08539161086082458\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 297/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0586513934640606e-05 val_loss : 0.08571121841669083\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 298/1000\n",
      "Steps: 0\n",
      "train_loss : 2.49956220045533e-05 val_loss : 0.08710630238056183\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 299/1000\n",
      "Steps: 0\n",
      "train_loss : 6.802828249874438e-06 val_loss : 0.08795978128910065\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 300/1000\n",
      "Steps: 0\n",
      "train_loss : 7.537980462757332e-06 val_loss : 0.08822744339704514\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 301/1000\n",
      "Steps: 0\n",
      "train_loss : 1.207857858389616e-05 val_loss : 0.08815941959619522\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 302/1000\n",
      "Steps: 0\n",
      "train_loss : 7.157477898545039e-06 val_loss : 0.0881146639585495\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 303/1000\n",
      "Steps: 0\n",
      "train_loss : 4.7005273813738315e-06 val_loss : 0.08803406357765198\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 304/1000\n",
      "Steps: 0\n",
      "train_loss : 7.733783860430776e-06 val_loss : 0.08788453042507172\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 305/1000\n",
      "Steps: 0\n",
      "train_loss : 7.727146362412896e-06 val_loss : 0.0886102020740509\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 306/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4339235758598078e-05 val_loss : 0.088958740234375\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 307/1000\n",
      "Steps: 0\n",
      "train_loss : 5.308330293019025e-06 val_loss : 0.08909008651971817\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 308/1000\n",
      "Steps: 0\n",
      "train_loss : 8.283534634756507e-06 val_loss : 0.08926062285900116\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 309/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0520970567995391e-05 val_loss : 0.0893496572971344\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 310/1000\n",
      "Steps: 0\n",
      "train_loss : 9.978135926758113e-06 val_loss : 0.09140105545520782\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 311/1000\n",
      "Steps: 0\n",
      "train_loss : 2.7235737843511742e-05 val_loss : 0.09262543171644211\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 312/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0242708998475792e-05 val_loss : 0.09326954931020737\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 313/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1176243970112409e-05 val_loss : 0.09357573837041855\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 314/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0819242805837349e-05 val_loss : 0.09397061914205551\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 315/1000\n",
      "Steps: 0\n",
      "train_loss : 4.2176723468401175e-06 val_loss : 0.0944574847817421\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 316/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0057551037334633e-05 val_loss : 0.09475640207529068\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 317/1000\n",
      "Steps: 0\n",
      "train_loss : 6.1034976170049046e-06 val_loss : 0.09437546879053116\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 318/1000\n",
      "Steps: 0\n",
      "train_loss : 1.039427891100786e-05 val_loss : 0.09380444884300232\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 319/1000\n",
      "Steps: 0\n",
      "train_loss : 9.338000705838567e-06 val_loss : 0.09339329600334167\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 320/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2964689540240215e-05 val_loss : 0.09306199848651886\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 321/1000\n",
      "Steps: 0\n",
      "train_loss : 7.678529181021077e-06 val_loss : 0.09291773289442062\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 322/1000\n",
      "Steps: 0\n",
      "train_loss : 9.247171362858353e-06 val_loss : 0.0948687344789505\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 323/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2093200803064974e-05 val_loss : 0.09640776365995407\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 324/1000\n",
      "Steps: 0\n",
      "train_loss : 1.553543268073554e-05 val_loss : 0.0970330536365509\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 325/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9305837736283137e-05 val_loss : 0.09741952270269394\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 326/1000\n",
      "Steps: 0\n",
      "train_loss : 2.056668055274713e-05 val_loss : 0.09749375283718109\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 327/1000\n",
      "Steps: 0\n",
      "train_loss : 3.099131038197811e-06 val_loss : 0.09752101451158524\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 328/1000\n",
      "Steps: 0\n",
      "train_loss : 4.002356399723795e-06 val_loss : 0.0975474864244461\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 329/1000\n",
      "Steps: 0\n",
      "train_loss : 8.529201113560703e-06 val_loss : 0.09722781926393509\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 330/1000\n",
      "Steps: 0\n",
      "train_loss : 6.642318885496934e-06 val_loss : 0.09683896601200104\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 331/1000\n",
      "Steps: 0\n",
      "train_loss : 8.438603640570363e-06 val_loss : 0.09658004343509674\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 332/1000\n",
      "Steps: 0\n",
      "train_loss : 1.068651682771815e-05 val_loss : 0.09628022462129593\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 333/1000\n",
      "Steps: 0\n",
      "train_loss : 1.673792095857607e-05 val_loss : 0.09582708775997162\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 334/1000\n",
      "Steps: 0\n",
      "train_loss : 4.259002685103041e-06 val_loss : 0.09559972584247589\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 335/1000\n",
      "Steps: 0\n",
      "train_loss : 6.885406384071757e-06 val_loss : 0.09561970829963684\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 336/1000\n",
      "Steps: 0\n",
      "train_loss : 1.262176624550193e-05 val_loss : 0.09771786630153656\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 337/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5072966942852872e-05 val_loss : 0.10148392617702484\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 338/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0631379819869834e-05 val_loss : 0.1036108061671257\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 339/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0998768988201846e-05 val_loss : 0.10500069707632065\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 340/1000\n",
      "Steps: 0\n",
      "train_loss : 1.646573508082838e-05 val_loss : 0.10533714294433594\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 341/1000\n",
      "Steps: 0\n",
      "train_loss : 5.328424100525808e-06 val_loss : 0.10507450997829437\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 342/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4226485154722468e-05 val_loss : 0.10493015497922897\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 343/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6765037730692712e-05 val_loss : 0.10468978434801102\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 344/1000\n",
      "Steps: 0\n",
      "train_loss : 3.896445733744258e-05 val_loss : 0.11241691559553146\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 345/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5788853852427563e-05 val_loss : 0.12002543359994888\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 346/1000\n",
      "Steps: 0\n",
      "train_loss : 6.245925385428564e-06 val_loss : 0.12430381774902344\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 347/1000\n",
      "Steps: 0\n",
      "train_loss : 8.828585737319373e-06 val_loss : 0.12665139138698578\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 348/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5535782813458356e-05 val_loss : 0.1277199387550354\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 349/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2858750216082626e-05 val_loss : 0.12845484912395477\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 350/1000\n",
      "Steps: 0\n",
      "train_loss : 5.954695927812281e-06 val_loss : 0.12894169986248016\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 351/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2622553265373427e-05 val_loss : 0.12913039326667786\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 352/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3184286285650159e-05 val_loss : 0.1287742406129837\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 353/1000\n",
      "Steps: 0\n",
      "train_loss : 7.770229649395332e-06 val_loss : 0.12857720255851746\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 354/1000\n",
      "Steps: 0\n",
      "train_loss : 6.755325392759914e-06 val_loss : 0.12840646505355835\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 355/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0165375681481236e-05 val_loss : 0.1282903105020523\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 356/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5842671621821864e-06 val_loss : 0.12878751754760742\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 357/1000\n",
      "Steps: 0\n",
      "train_loss : 7.616632592544192e-06 val_loss : 0.12895333766937256\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 358/1000\n",
      "Steps: 0\n",
      "train_loss : 4.40168569468824e-06 val_loss : 0.1291668862104416\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 359/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9618473629634535e-06 val_loss : 0.12928107380867004\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 360/1000\n",
      "Steps: 0\n",
      "train_loss : 1.539117114361943e-05 val_loss : 0.12663249671459198\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 361/1000\n",
      "Steps: 0\n",
      "train_loss : 9.083575702106827e-06 val_loss : 0.12048634886741638\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 362/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0967279831675113e-05 val_loss : 0.1166427955031395\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 363/1000\n",
      "Steps: 0\n",
      "train_loss : 4.7600448738194245e-06 val_loss : 0.11431007832288742\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 364/1000\n",
      "Steps: 0\n",
      "train_loss : 5.550607443183253e-06 val_loss : 0.11270962655544281\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 365/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8334403199560258e-05 val_loss : 0.11156997084617615\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 366/1000\n",
      "Steps: 0\n",
      "train_loss : 5.219506493858716e-06 val_loss : 0.11172203719615936\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 367/1000\n",
      "Steps: 0\n",
      "train_loss : 7.742841012259305e-06 val_loss : 0.11168961226940155\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 368/1000\n",
      "Steps: 0\n",
      "train_loss : 9.488988260386577e-06 val_loss : 0.11145716160535812\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 369/1000\n",
      "Steps: 0\n",
      "train_loss : 4.856559849031328e-06 val_loss : 0.11127084493637085\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 370/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2801933615946837e-05 val_loss : 0.11104137450456619\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 371/1000\n",
      "Steps: 0\n",
      "train_loss : 3.0938130976210233e-06 val_loss : 0.11039116978645325\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 372/1000\n",
      "Steps: 0\n",
      "train_loss : 7.698860247273843e-06 val_loss : 0.10977298766374588\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 373/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1500889786475455e-05 val_loss : 0.10932376235723495\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 374/1000\n",
      "Steps: 0\n",
      "train_loss : 6.804437865071122e-06 val_loss : 0.10907384008169174\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 375/1000\n",
      "Steps: 0\n",
      "train_loss : 4.6609166759026264e-06 val_loss : 0.10888300836086273\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 376/1000\n",
      "Steps: 0\n",
      "train_loss : 5.483148083840206e-06 val_loss : 0.10867509245872498\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 377/1000\n",
      "Steps: 0\n",
      "train_loss : 4.129733076752018e-06 val_loss : 0.10843464732170105\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 378/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9932463879968053e-05 val_loss : 0.10818900167942047\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 379/1000\n",
      "Steps: 0\n",
      "train_loss : 2.665593086703666e-06 val_loss : 0.10794350504875183\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 380/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6953122446448106e-06 val_loss : 0.10817009210586548\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 381/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4432650812068459e-05 val_loss : 0.10807088017463684\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 382/1000\n",
      "Steps: 0\n",
      "train_loss : 5.409725986282865e-06 val_loss : 0.1078452467918396\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 383/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8858219078765615e-05 val_loss : 0.10756351053714752\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 384/1000\n",
      "Steps: 0\n",
      "train_loss : 9.355427403079375e-06 val_loss : 0.10721705108880997\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 385/1000\n",
      "Steps: 0\n",
      "train_loss : 4.702748930185407e-06 val_loss : 0.10701264441013336\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 386/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3097227986236249e-05 val_loss : 0.10680227726697922\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 387/1000\n",
      "Steps: 0\n",
      "train_loss : 2.933990049314161e-06 val_loss : 0.1064518466591835\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 388/1000\n",
      "Steps: 0\n",
      "train_loss : 2.512368127440823e-05 val_loss : 0.106129951775074\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 389/1000\n",
      "Steps: 0\n",
      "train_loss : 3.70286154520727e-06 val_loss : 0.10586851090192795\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 390/1000\n",
      "Steps: 0\n",
      "train_loss : 1.367101921232461e-05 val_loss : 0.10573504120111465\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 391/1000\n",
      "Steps: 0\n",
      "train_loss : 4.872558611168642e-06 val_loss : 0.10563322901725769\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 392/1000\n",
      "Steps: 0\n",
      "train_loss : 9.11872552933346e-06 val_loss : 0.10544344782829285\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 393/1000\n",
      "Steps: 0\n",
      "train_loss : 6.819706814553683e-06 val_loss : 0.10521851480007172\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 394/1000\n",
      "Steps: 0\n",
      "train_loss : 6.247687218774445e-06 val_loss : 0.10498505085706711\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 395/1000\n",
      "Steps: 0\n",
      "train_loss : 5.040423386049042e-06 val_loss : 0.10476336628198624\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 396/1000\n",
      "Steps: 0\n",
      "train_loss : 4.222764277983515e-06 val_loss : 0.10444340854883194\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 397/1000\n",
      "Steps: 0\n",
      "train_loss : 8.73057129240351e-06 val_loss : 0.1042151004076004\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 398/1000\n",
      "Steps: 0\n",
      "train_loss : 9.768502667384383e-06 val_loss : 0.10396537184715271\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 399/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5509501633914623e-05 val_loss : 0.10321284830570221\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 400/1000\n",
      "Steps: 0\n",
      "train_loss : 4.8423978910250295e-06 val_loss : 0.10179466009140015\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 401/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5854461543749492e-06 val_loss : 0.10086502879858017\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 402/1000\n",
      "Steps: 0\n",
      "train_loss : 5.2152857790588316e-06 val_loss : 0.10030840337276459\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 403/1000\n",
      "Steps: 0\n",
      "train_loss : 8.050197777720314e-06 val_loss : 0.09988681972026825\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 404/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4211201943226115e-05 val_loss : 0.09960909932851791\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 405/1000\n",
      "Steps: 0\n",
      "train_loss : 4.021494396511116e-06 val_loss : 0.09938930720090866\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 406/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5774884417396606e-05 val_loss : 0.09974455088376999\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 407/1000\n",
      "Steps: 0\n",
      "train_loss : 2.7972717077773266e-06 val_loss : 0.10005127638578415\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 408/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1024440732398944e-05 val_loss : 0.09872916340827942\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 409/1000\n",
      "Steps: 0\n",
      "train_loss : 6.192446130626195e-06 val_loss : 0.09640030562877655\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 410/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8971885768669383e-06 val_loss : 0.09476485103368759\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 411/1000\n",
      "Steps: 0\n",
      "train_loss : 4.015133390566916e-06 val_loss : 0.09369856119155884\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 412/1000\n",
      "Steps: 0\n",
      "train_loss : 6.329022323825484e-06 val_loss : 0.0930672287940979\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 413/1000\n",
      "Steps: 0\n",
      "train_loss : 5.561992304592423e-06 val_loss : 0.09274502843618393\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 414/1000\n",
      "Steps: 0\n",
      "train_loss : 6.679421622379777e-06 val_loss : 0.09256532043218613\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 415/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7527666295791276e-05 val_loss : 0.09236665070056915\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 416/1000\n",
      "Steps: 0\n",
      "train_loss : 3.643494778771128e-06 val_loss : 0.09219946712255478\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 417/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2133869947538186e-06 val_loss : 0.09267448633909225\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 418/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1664126361665694e-05 val_loss : 0.09287969768047333\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 419/1000\n",
      "Steps: 0\n",
      "train_loss : 5.032780609326437e-06 val_loss : 0.09282144159078598\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 420/1000\n",
      "Steps: 0\n",
      "train_loss : 4.01778120817653e-06 val_loss : 0.09279312938451767\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 421/1000\n",
      "Steps: 0\n",
      "train_loss : 8.611310232709001e-06 val_loss : 0.09274066239595413\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 422/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3649702896145755e-05 val_loss : 0.09256789088249207\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 423/1000\n",
      "Steps: 0\n",
      "train_loss : 9.41648874004386e-06 val_loss : 0.0924246534705162\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 424/1000\n",
      "Steps: 0\n",
      "train_loss : 4.603334994612851e-06 val_loss : 0.09238001704216003\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 425/1000\n",
      "Steps: 0\n",
      "train_loss : 8.635547786184361e-06 val_loss : 0.09261756390333176\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 426/1000\n",
      "Steps: 0\n",
      "train_loss : 8.849856939718848e-06 val_loss : 0.09271082282066345\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 427/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8662517593147642e-06 val_loss : 0.09266982972621918\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 428/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3130110392012285e-05 val_loss : 0.09257806837558746\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 429/1000\n",
      "Steps: 0\n",
      "train_loss : 2.754657685954953e-06 val_loss : 0.09271983802318573\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 430/1000\n",
      "Steps: 0\n",
      "train_loss : 4.242531593945386e-06 val_loss : 0.09307320415973663\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 431/1000\n",
      "Steps: 0\n",
      "train_loss : 6.778575675525645e-06 val_loss : 0.09332402050495148\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 432/1000\n",
      "Steps: 0\n",
      "train_loss : 7.05900674233817e-06 val_loss : 0.09329158067703247\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 433/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8136000647928086e-06 val_loss : 0.0931253656744957\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 434/1000\n",
      "Steps: 0\n",
      "train_loss : 5.025225436838809e-06 val_loss : 0.09298411756753922\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 435/1000\n",
      "Steps: 0\n",
      "train_loss : 2.44700952976018e-06 val_loss : 0.09289565682411194\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 436/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4445633627246935e-05 val_loss : 0.09274981170892715\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 437/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4105213728707895e-06 val_loss : 0.09253475815057755\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 438/1000\n",
      "Steps: 0\n",
      "train_loss : 5.120250830259465e-06 val_loss : 0.09370293468236923\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 439/1000\n",
      "Steps: 0\n",
      "train_loss : 9.040548917482738e-06 val_loss : 0.0958247035741806\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 440/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6764668430369057e-06 val_loss : 0.09703068435192108\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 441/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4674558605729545e-06 val_loss : 0.09771091490983963\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 442/1000\n",
      "Steps: 0\n",
      "train_loss : 2.160901550212202e-05 val_loss : 0.09818387776613235\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 443/1000\n",
      "Steps: 0\n",
      "train_loss : 9.19689490501696e-06 val_loss : 0.09826814383268356\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 444/1000\n",
      "Steps: 0\n",
      "train_loss : 7.668250137271571e-06 val_loss : 0.09821657091379166\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 445/1000\n",
      "Steps: 0\n",
      "train_loss : 9.867402002328163e-06 val_loss : 0.09806104749441147\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 446/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6857846958373557e-06 val_loss : 0.09788160026073456\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 447/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6673496307694224e-06 val_loss : 0.0977887436747551\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 448/1000\n",
      "Steps: 0\n",
      "train_loss : 3.175616880639609e-05 val_loss : 0.09748219698667526\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 449/1000\n",
      "Steps: 0\n",
      "train_loss : 4.195770247861219e-06 val_loss : 0.0971243679523468\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 450/1000\n",
      "Steps: 0\n",
      "train_loss : 1.659543848688827e-05 val_loss : 0.09672310203313828\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 451/1000\n",
      "Steps: 0\n",
      "train_loss : 5.434882018562348e-06 val_loss : 0.0961291640996933\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 452/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6720550579284465e-06 val_loss : 0.09565848112106323\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 453/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4909441322051863e-06 val_loss : 0.09534316509962082\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 454/1000\n",
      "Steps: 0\n",
      "train_loss : 5.040188923999267e-06 val_loss : 0.09500572085380554\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 455/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3537158602616728e-05 val_loss : 0.09461591392755508\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 456/1000\n",
      "Steps: 0\n",
      "train_loss : 2.168667890600773e-06 val_loss : 0.0944635272026062\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 457/1000\n",
      "Steps: 0\n",
      "train_loss : 2.070681398436136e-06 val_loss : 0.09434869885444641\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 458/1000\n",
      "Steps: 0\n",
      "train_loss : 2.018181857010859e-06 val_loss : 0.09424888342618942\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 459/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0166982787040978e-05 val_loss : 0.09431659430265427\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 460/1000\n",
      "Steps: 0\n",
      "train_loss : 5.159389797881886e-06 val_loss : 0.09500379860401154\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 461/1000\n",
      "Steps: 0\n",
      "train_loss : 5.519836818734802e-06 val_loss : 0.09551005810499191\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 462/1000\n",
      "Steps: 0\n",
      "train_loss : 5.555311690841336e-06 val_loss : 0.0957227423787117\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 463/1000\n",
      "Steps: 0\n",
      "train_loss : 2.727350747022683e-06 val_loss : 0.09585651755332947\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 464/1000\n",
      "Steps: 0\n",
      "train_loss : 2.7470546569929867e-06 val_loss : 0.09589726477861404\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 465/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2867333285603308e-06 val_loss : 0.0959194153547287\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 466/1000\n",
      "Steps: 0\n",
      "train_loss : 3.867102685717328e-06 val_loss : 0.09604710340499878\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 467/1000\n",
      "Steps: 0\n",
      "train_loss : 4.780515291713528e-06 val_loss : 0.0960833728313446\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 468/1000\n",
      "Steps: 0\n",
      "train_loss : 9.30025281888902e-06 val_loss : 0.09593935310840607\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 469/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2029468823347997e-06 val_loss : 0.09585004299879074\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 470/1000\n",
      "Steps: 0\n",
      "train_loss : 3.317479820452718e-06 val_loss : 0.09594070166349411\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 471/1000\n",
      "Steps: 0\n",
      "train_loss : 6.752999223635925e-06 val_loss : 0.09609704464673996\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 472/1000\n",
      "Steps: 0\n",
      "train_loss : 5.470584198974393e-06 val_loss : 0.09639199078083038\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 473/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5308777779287085e-06 val_loss : 0.09697410464286804\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 474/1000\n",
      "Steps: 0\n",
      "train_loss : 4.669961435865844e-06 val_loss : 0.0973113626241684\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 475/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4682343198255693e-06 val_loss : 0.09746307134628296\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 476/1000\n",
      "Steps: 0\n",
      "train_loss : 7.443411266194744e-06 val_loss : 0.09741248190402985\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 477/1000\n",
      "Steps: 0\n",
      "train_loss : 4.177166471208693e-06 val_loss : 0.09731101989746094\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 478/1000\n",
      "Steps: 0\n",
      "train_loss : 3.995240319909499e-06 val_loss : 0.09721250087022781\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 479/1000\n",
      "Steps: 0\n",
      "train_loss : 7.487057558819288e-06 val_loss : 0.09734773635864258\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 480/1000\n",
      "Steps: 0\n",
      "train_loss : 3.865335402508663e-06 val_loss : 0.09867540746927261\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 481/1000\n",
      "Steps: 0\n",
      "train_loss : 7.530870095706632e-06 val_loss : 0.09933155030012131\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 482/1000\n",
      "Steps: 0\n",
      "train_loss : 2.074463768053647e-06 val_loss : 0.09941449016332626\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 483/1000\n",
      "Steps: 0\n",
      "train_loss : 6.3612134511004115e-06 val_loss : 0.09932776540517807\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 484/1000\n",
      "Steps: 0\n",
      "train_loss : 3.208671040511035e-06 val_loss : 0.09934105724096298\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 485/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9563039117542758e-06 val_loss : 0.09942931681871414\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 486/1000\n",
      "Steps: 0\n",
      "train_loss : 4.944909267123876e-06 val_loss : 0.09942694753408432\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 487/1000\n",
      "Steps: 0\n",
      "train_loss : 3.187521915037905e-06 val_loss : 0.09940411895513535\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 488/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0885120494208422e-05 val_loss : 0.09956816583871841\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 489/1000\n",
      "Steps: 0\n",
      "train_loss : 7.312903892398026e-06 val_loss : 0.09982384741306305\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 490/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1350450398595057e-05 val_loss : 0.09989484399557114\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 491/1000\n",
      "Steps: 0\n",
      "train_loss : 1.870965297712246e-06 val_loss : 0.09989556670188904\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 492/1000\n",
      "Steps: 0\n",
      "train_loss : 5.154152779596188e-06 val_loss : 0.0998387485742569\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 493/1000\n",
      "Steps: 0\n",
      "train_loss : 5.228419109926108e-06 val_loss : 0.09966068714857101\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 494/1000\n",
      "Steps: 0\n",
      "train_loss : 1.959715649491045e-06 val_loss : 0.09952323883771896\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 495/1000\n",
      "Steps: 0\n",
      "train_loss : 4.9071488291474456e-06 val_loss : 0.09929083287715912\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 496/1000\n",
      "Steps: 0\n",
      "train_loss : 2.220146720333105e-06 val_loss : 0.09905747324228287\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 497/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0520504361011263e-06 val_loss : 0.09894898533821106\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 498/1000\n",
      "Steps: 0\n",
      "train_loss : 3.3343097868510086e-06 val_loss : 0.09862704575061798\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 499/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2915955920789201e-06 val_loss : 0.09819364547729492\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 500/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1876044598911903e-06 val_loss : 0.09796099364757538\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 501/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2266415956219134e-05 val_loss : 0.09786068648099899\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 502/1000\n",
      "Steps: 0\n",
      "train_loss : 5.024914912610257e-06 val_loss : 0.09751956909894943\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 503/1000\n",
      "Steps: 0\n",
      "train_loss : 3.900608112417103e-06 val_loss : 0.09699185937643051\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 504/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5990986532397074e-06 val_loss : 0.09756894409656525\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 505/1000\n",
      "Steps: 0\n",
      "train_loss : 3.7233195882890867e-06 val_loss : 0.0980953723192215\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 506/1000\n",
      "Steps: 0\n",
      "train_loss : 3.7380368695494324e-06 val_loss : 0.09832185506820679\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 507/1000\n",
      "Steps: 0\n",
      "train_loss : 5.175838762738749e-06 val_loss : 0.09858985245227814\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 508/1000\n",
      "Steps: 0\n",
      "train_loss : 1.677201681218321e-05 val_loss : 0.098683662712574\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 509/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6637066614275683e-06 val_loss : 0.09879859536886215\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 510/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5662503222511076e-06 val_loss : 0.09876108169555664\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 511/1000\n",
      "Steps: 0\n",
      "train_loss : 3.328405091451714e-06 val_loss : 0.09869324415922165\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 512/1000\n",
      "Steps: 0\n",
      "train_loss : 3.954405431727537e-06 val_loss : 0.09877143055200577\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 513/1000\n",
      "Steps: 0\n",
      "train_loss : 4.611804786236462e-06 val_loss : 0.09862799942493439\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 514/1000\n",
      "Steps: 0\n",
      "train_loss : 4.941696306559606e-06 val_loss : 0.0983637198805809\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 515/1000\n",
      "Steps: 0\n",
      "train_loss : 4.495199121379301e-06 val_loss : 0.09813227504491806\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 516/1000\n",
      "Steps: 0\n",
      "train_loss : 4.43402260827952e-06 val_loss : 0.09790843725204468\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 517/1000\n",
      "Steps: 0\n",
      "train_loss : 2.597076365873363e-06 val_loss : 0.09835559874773026\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 518/1000\n",
      "Steps: 0\n",
      "train_loss : 1.228644060802253e-06 val_loss : 0.09862246364355087\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 519/1000\n",
      "Steps: 0\n",
      "train_loss : 4.530267588620518e-06 val_loss : 0.09870091080665588\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 520/1000\n",
      "Steps: 0\n",
      "train_loss : 2.035718620163607e-06 val_loss : 0.0987299308180809\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 521/1000\n",
      "Steps: 0\n",
      "train_loss : 3.657171026816286e-06 val_loss : 0.098687082529068\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 522/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1899849642181833e-06 val_loss : 0.09847914427518845\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 523/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4954231125539083e-06 val_loss : 0.09821716696023941\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 524/1000\n",
      "Steps: 0\n",
      "train_loss : 6.413203129795874e-06 val_loss : 0.09795314818620682\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 525/1000\n",
      "Steps: 0\n",
      "train_loss : 9.717350167193217e-06 val_loss : 0.09802501648664474\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 526/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2406034247524074e-06 val_loss : 0.09833341091871262\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 527/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5457165608931972e-06 val_loss : 0.09852557629346848\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 528/1000\n",
      "Steps: 0\n",
      "train_loss : 4.958402973898046e-06 val_loss : 0.09852270036935806\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 529/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8118583557557033e-06 val_loss : 0.09857452660799026\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 530/1000\n",
      "Steps: 0\n",
      "train_loss : 2.823216362912717e-06 val_loss : 0.09844379127025604\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 531/1000\n",
      "Steps: 0\n",
      "train_loss : 2.282416650700725e-06 val_loss : 0.09831806272268295\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 532/1000\n",
      "Steps: 0\n",
      "train_loss : 4.01687859437061e-06 val_loss : 0.09820131212472916\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 533/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3073650851301864e-06 val_loss : 0.09815793484449387\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 534/1000\n",
      "Steps: 0\n",
      "train_loss : 8.636703742581631e-06 val_loss : 0.09800375252962112\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 535/1000\n",
      "Steps: 0\n",
      "train_loss : 3.8819539952328345e-06 val_loss : 0.0979321151971817\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 536/1000\n",
      "Steps: 0\n",
      "train_loss : 5.139549115540376e-06 val_loss : 0.09796715527772903\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 537/1000\n",
      "Steps: 0\n",
      "train_loss : 3.675060673913322e-06 val_loss : 0.09796477109193802\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 538/1000\n",
      "Steps: 0\n",
      "train_loss : 9.2948959320438e-07 val_loss : 0.0978831872344017\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 539/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1371243033408973e-05 val_loss : 0.09818920493125916\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 540/1000\n",
      "Steps: 0\n",
      "train_loss : 2.435526600663707e-06 val_loss : 0.09853629767894745\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 541/1000\n",
      "Steps: 0\n",
      "train_loss : 8.370272908564402e-06 val_loss : 0.09852970391511917\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 542/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1205646703492677e-06 val_loss : 0.09898827970027924\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 543/1000\n",
      "Steps: 0\n",
      "train_loss : 2.442297085281098e-06 val_loss : 0.09960662573575974\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 544/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9548726868379163e-06 val_loss : 0.09996727108955383\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 545/1000\n",
      "Steps: 0\n",
      "train_loss : 2.819486701355345e-06 val_loss : 0.10029920935630798\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 546/1000\n",
      "Steps: 0\n",
      "train_loss : 4.9902065939022576e-06 val_loss : 0.10109890252351761\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 547/1000\n",
      "Steps: 0\n",
      "train_loss : 1.987637179468038e-06 val_loss : 0.10121189057826996\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 548/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7716619709062797e-05 val_loss : 0.10127203911542892\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 549/1000\n",
      "Steps: 0\n",
      "train_loss : 8.56876333443779e-06 val_loss : 0.10059783607721329\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 550/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0524234653530583e-06 val_loss : 0.09967472404241562\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 551/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4015854478420806e-06 val_loss : 0.09916018694639206\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 552/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7778488228259448e-06 val_loss : 0.09883692115545273\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 553/1000\n",
      "Steps: 0\n",
      "train_loss : 6.255197260429668e-06 val_loss : 0.09859251976013184\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 554/1000\n",
      "Steps: 0\n",
      "train_loss : 5.089713715733523e-06 val_loss : 0.09837379306554794\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 555/1000\n",
      "Steps: 0\n",
      "train_loss : 4.180239164952581e-06 val_loss : 0.09814492613077164\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 556/1000\n",
      "Steps: 0\n",
      "train_loss : 1.93727058785953e-06 val_loss : 0.09806282818317413\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 557/1000\n",
      "Steps: 0\n",
      "train_loss : 5.772566817086045e-06 val_loss : 0.09807799756526947\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 558/1000\n",
      "Steps: 0\n",
      "train_loss : 7.89774524321274e-06 val_loss : 0.09825517982244492\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 559/1000\n",
      "Steps: 0\n",
      "train_loss : 2.859240981933908e-06 val_loss : 0.09838587790727615\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 560/1000\n",
      "Steps: 0\n",
      "train_loss : 6.259086916315937e-06 val_loss : 0.0984421893954277\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 561/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4328335289046664e-06 val_loss : 0.09847351163625717\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 562/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6874095144412424e-06 val_loss : 0.09844225645065308\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 563/1000\n",
      "Steps: 0\n",
      "train_loss : 6.443644443265839e-06 val_loss : 0.09816998243331909\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 564/1000\n",
      "Steps: 0\n",
      "train_loss : 4.040041997654953e-06 val_loss : 0.0978458821773529\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 565/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2763642075697136e-06 val_loss : 0.09775648266077042\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 566/1000\n",
      "Steps: 0\n",
      "train_loss : 4.926120536197232e-06 val_loss : 0.09749460965394974\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 567/1000\n",
      "Steps: 0\n",
      "train_loss : 2.357327588242697e-06 val_loss : 0.09720800071954727\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 568/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0014276202573454e-06 val_loss : 0.09692578762769699\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 569/1000\n",
      "Steps: 0\n",
      "train_loss : 8.145571374029715e-06 val_loss : 0.09672874957323074\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 570/1000\n",
      "Steps: 0\n",
      "train_loss : 8.684203194775364e-06 val_loss : 0.09646985679864883\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 571/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5654954239607832e-06 val_loss : 0.09621045738458633\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 572/1000\n",
      "Steps: 0\n",
      "train_loss : 5.329191844793968e-06 val_loss : 0.09598542004823685\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 573/1000\n",
      "Steps: 0\n",
      "train_loss : 5.855509502339373e-06 val_loss : 0.09570322185754776\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 574/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8864400206884967e-06 val_loss : 0.09551771730184555\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 575/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1019687974567206e-06 val_loss : 0.09546760469675064\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 576/1000\n",
      "Steps: 0\n",
      "train_loss : 4.5608447493350465e-06 val_loss : 0.09539623558521271\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 577/1000\n",
      "Steps: 0\n",
      "train_loss : 7.399684403708307e-06 val_loss : 0.09564780443906784\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 578/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5986064599692325e-06 val_loss : 0.09757068753242493\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 579/1000\n",
      "Steps: 0\n",
      "train_loss : 8.284453028295501e-06 val_loss : 0.0995447188615799\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 580/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5634321559664385e-06 val_loss : 0.10063488781452179\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 581/1000\n",
      "Steps: 0\n",
      "train_loss : 1.828164425887735e-06 val_loss : 0.10115709155797958\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 582/1000\n",
      "Steps: 0\n",
      "train_loss : 2.054605005241683e-06 val_loss : 0.10119428485631943\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 583/1000\n",
      "Steps: 0\n",
      "train_loss : 3.546130690779137e-06 val_loss : 0.10115896165370941\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 584/1000\n",
      "Steps: 0\n",
      "train_loss : 4.746949412037793e-06 val_loss : 0.10097316652536392\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 585/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0759565813932567e-06 val_loss : 0.1007475033402443\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 586/1000\n",
      "Steps: 0\n",
      "train_loss : 3.451127193443426e-06 val_loss : 0.10043817013502121\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 587/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2431781357236105e-06 val_loss : 0.1001424565911293\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 588/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1910533575919542e-06 val_loss : 0.09989987313747406\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 589/1000\n",
      "Steps: 0\n",
      "train_loss : 2.9043519646165806e-06 val_loss : 0.09924154728651047\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 590/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8642339853158774e-06 val_loss : 0.09860523045063019\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 591/1000\n",
      "Steps: 0\n",
      "train_loss : 3.527879437115189e-06 val_loss : 0.09844764322042465\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 592/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2410792496430077e-06 val_loss : 0.09824331104755402\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 593/1000\n",
      "Steps: 0\n",
      "train_loss : 1.689555502082385e-06 val_loss : 0.09796515107154846\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 594/1000\n",
      "Steps: 0\n",
      "train_loss : 2.522958249073781e-06 val_loss : 0.09777819365262985\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 595/1000\n",
      "Steps: 0\n",
      "train_loss : 2.6524048280407443e-06 val_loss : 0.09737282246351242\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 596/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0228610429408036e-05 val_loss : 0.09673229604959488\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 597/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1828639887644385e-06 val_loss : 0.09607848525047302\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 598/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3169396368084564e-06 val_loss : 0.0950424000620842\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 599/1000\n",
      "Steps: 0\n",
      "train_loss : 4.259757838553924e-06 val_loss : 0.09437382966279984\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 600/1000\n",
      "Steps: 0\n",
      "train_loss : 2.9602919369153824e-06 val_loss : 0.09416513890028\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 601/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4691554955325047e-06 val_loss : 0.09403007477521896\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 602/1000\n",
      "Steps: 0\n",
      "train_loss : 4.804243670264441e-06 val_loss : 0.09387663751840591\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 603/1000\n",
      "Steps: 0\n",
      "train_loss : 2.102444528873093e-06 val_loss : 0.09363165497779846\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 604/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6742036791583815e-06 val_loss : 0.09349021315574646\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 605/1000\n",
      "Steps: 0\n",
      "train_loss : 2.9612845537485553e-06 val_loss : 0.0940532237291336\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 606/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3780761949865337e-06 val_loss : 0.09520070999860764\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 607/1000\n",
      "Steps: 0\n",
      "train_loss : 8.624258384770656e-07 val_loss : 0.09584759175777435\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 608/1000\n",
      "Steps: 0\n",
      "train_loss : 7.920190853383246e-07 val_loss : 0.09628327935934067\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 609/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2771065854622065e-06 val_loss : 0.09652477502822876\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 610/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9634429548887056e-06 val_loss : 0.09663964807987213\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 611/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4686141668107665e-06 val_loss : 0.09655572474002838\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 612/1000\n",
      "Steps: 0\n",
      "train_loss : 5.638963234844141e-06 val_loss : 0.09644168615341187\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 613/1000\n",
      "Steps: 0\n",
      "train_loss : 5.4253725352282345e-06 val_loss : 0.0962425172328949\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 614/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3236627040669191e-06 val_loss : 0.09610612690448761\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 615/1000\n",
      "Steps: 0\n",
      "train_loss : 9.19525416804845e-06 val_loss : 0.09590699523687363\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 616/1000\n",
      "Steps: 0\n",
      "train_loss : 8.396892269502132e-07 val_loss : 0.09579843282699585\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 617/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1582497154781776e-06 val_loss : 0.09546799957752228\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 618/1000\n",
      "Steps: 0\n",
      "train_loss : 8.938451287576754e-06 val_loss : 0.09499754756689072\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 619/1000\n",
      "Steps: 0\n",
      "train_loss : 2.395330318449851e-06 val_loss : 0.09473194926977158\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 620/1000\n",
      "Steps: 0\n",
      "train_loss : 6.843470671924479e-07 val_loss : 0.09445203095674515\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 621/1000\n",
      "Steps: 0\n",
      "train_loss : 1.604248997466584e-06 val_loss : 0.09423589706420898\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 622/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0748618510424423e-06 val_loss : 0.09410324692726135\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 623/1000\n",
      "Steps: 0\n",
      "train_loss : 6.330932417597523e-06 val_loss : 0.0941561758518219\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 624/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0248529946466079e-06 val_loss : 0.09427421540021896\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 625/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1187412212620984e-06 val_loss : 0.09445176273584366\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 626/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9194875420680548e-06 val_loss : 0.09451653808355331\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 627/1000\n",
      "Steps: 0\n",
      "train_loss : 1.807315538826515e-06 val_loss : 0.09451516717672348\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 628/1000\n",
      "Steps: 0\n",
      "train_loss : 2.862304185669018e-06 val_loss : 0.0945579782128334\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 629/1000\n",
      "Steps: 0\n",
      "train_loss : 2.429982794183161e-06 val_loss : 0.09439025074243546\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 630/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3075250965121084e-06 val_loss : 0.09508875757455826\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 631/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0889437078276388e-06 val_loss : 0.09643886983394623\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 632/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8348696769976414e-06 val_loss : 0.09722163528203964\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 633/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5432329849195414e-06 val_loss : 0.09780562669038773\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 634/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2868677149290305e-06 val_loss : 0.09812592715024948\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 635/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4253179952561367e-05 val_loss : 0.09813372790813446\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 636/1000\n",
      "Steps: 0\n",
      "train_loss : 1.605737085697001e-06 val_loss : 0.09784391522407532\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 637/1000\n",
      "Steps: 0\n",
      "train_loss : 7.916503022897814e-07 val_loss : 0.09775570034980774\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 638/1000\n",
      "Steps: 0\n",
      "train_loss : 5.059236544013857e-06 val_loss : 0.0976189449429512\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 639/1000\n",
      "Steps: 0\n",
      "train_loss : 2.791102659216449e-06 val_loss : 0.09746287763118744\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 640/1000\n",
      "Steps: 0\n",
      "train_loss : 5.5938940789701516e-06 val_loss : 0.09725511819124222\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 641/1000\n",
      "Steps: 0\n",
      "train_loss : 4.091563144470456e-06 val_loss : 0.09700528532266617\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 642/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3907327286233339e-06 val_loss : 0.0967467874288559\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 643/1000\n",
      "Steps: 0\n",
      "train_loss : 4.446074812847201e-06 val_loss : 0.09629283845424652\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 644/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6623396646764376e-06 val_loss : 0.09617026150226593\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 645/1000\n",
      "Steps: 0\n",
      "train_loss : 5.56332013559313e-06 val_loss : 0.09607543796300888\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 646/1000\n",
      "Steps: 0\n",
      "train_loss : 6.981378902537472e-07 val_loss : 0.0958293080329895\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 647/1000\n",
      "Steps: 0\n",
      "train_loss : 7.856731798483452e-07 val_loss : 0.09579877555370331\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 648/1000\n",
      "Steps: 0\n",
      "train_loss : 1.758100825099973e-06 val_loss : 0.09533742815256119\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 649/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8307953837393143e-06 val_loss : 0.0950673520565033\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 650/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3550912828795845e-06 val_loss : 0.09493961185216904\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 651/1000\n",
      "Steps: 0\n",
      "train_loss : 2.485828451881389e-06 val_loss : 0.09473006427288055\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 652/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5599498087558457e-06 val_loss : 0.09464430809020996\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 653/1000\n",
      "Steps: 0\n",
      "train_loss : 8.754755313589158e-07 val_loss : 0.09481640160083771\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 654/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0252393110476987e-06 val_loss : 0.09488086402416229\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 655/1000\n",
      "Steps: 0\n",
      "train_loss : 8.911209334883097e-07 val_loss : 0.09488668292760849\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 656/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1210883573985484e-06 val_loss : 0.09470755606889725\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 657/1000\n",
      "Steps: 0\n",
      "train_loss : 4.167730082826893e-06 val_loss : 0.09499593824148178\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 658/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2368764004122568e-06 val_loss : 0.09671573340892792\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 659/1000\n",
      "Steps: 0\n",
      "train_loss : 2.13339948373914e-06 val_loss : 0.09761838614940643\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 660/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6811571661132803e-06 val_loss : 0.09800518304109573\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 661/1000\n",
      "Steps: 0\n",
      "train_loss : 5.340050876156965e-06 val_loss : 0.0982053279876709\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 662/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5479742614843417e-06 val_loss : 0.09835191816091537\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 663/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4724342154058833e-06 val_loss : 0.09826646745204926\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 664/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1824790831838071e-06 val_loss : 0.09818419069051743\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 665/1000\n",
      "Steps: 0\n",
      "train_loss : 8.225694188013222e-07 val_loss : 0.09811951220035553\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 666/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2483558211661147e-06 val_loss : 0.09818235039710999\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 667/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6001608400983968e-06 val_loss : 0.0981113612651825\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 668/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2551198921073591e-06 val_loss : 0.0980992242693901\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 669/1000\n",
      "Steps: 0\n",
      "train_loss : 2.787326073416807e-06 val_loss : 0.09832398593425751\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 670/1000\n",
      "Steps: 0\n",
      "train_loss : 2.406427179835191e-06 val_loss : 0.09860331565141678\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 671/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6471216099489539e-06 val_loss : 0.09880296140909195\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 672/1000\n",
      "Steps: 0\n",
      "train_loss : 1.11801193725114e-06 val_loss : 0.09890081733465195\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 673/1000\n",
      "Steps: 0\n",
      "train_loss : 5.073888729612008e-07 val_loss : 0.09896312654018402\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 674/1000\n",
      "Steps: 0\n",
      "train_loss : 6.053610519529684e-06 val_loss : 0.0989149883389473\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 675/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5330516134781646e-06 val_loss : 0.09890586137771606\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 676/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1195012547204898e-06 val_loss : 0.098675936460495\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 677/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3061117360612117e-06 val_loss : 0.09916835278272629\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 678/1000\n",
      "Steps: 0\n",
      "train_loss : 8.542659080745808e-06 val_loss : 0.10031042248010635\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 679/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6743107465799766e-06 val_loss : 0.10090155154466629\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 680/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1481842534522002e-06 val_loss : 0.10113469511270523\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 681/1000\n",
      "Steps: 0\n",
      "train_loss : 4.923574854842627e-06 val_loss : 0.10109613090753555\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 682/1000\n",
      "Steps: 0\n",
      "train_loss : 8.709988890132081e-07 val_loss : 0.10099408775568008\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 683/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2036802132797675e-06 val_loss : 0.10203603655099869\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 684/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3262717374118437e-06 val_loss : 0.1025540679693222\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 685/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9720445294524325e-06 val_loss : 0.10296805202960968\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 686/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3117184579414242e-06 val_loss : 0.10331235826015472\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 687/1000\n",
      "Steps: 0\n",
      "train_loss : 8.534943987115184e-07 val_loss : 0.10348103940486908\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 688/1000\n",
      "Steps: 0\n",
      "train_loss : 8.810555470972758e-07 val_loss : 0.10353126376867294\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 689/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3202953837776476e-06 val_loss : 0.10378020256757736\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 690/1000\n",
      "Steps: 0\n",
      "train_loss : 2.7622760171652772e-06 val_loss : 0.1048695296049118\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 691/1000\n",
      "Steps: 0\n",
      "train_loss : 8.437965163921036e-07 val_loss : 0.10486076027154922\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 692/1000\n",
      "Steps: 0\n",
      "train_loss : 7.033446777882091e-07 val_loss : 0.10504686087369919\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 693/1000\n",
      "Steps: 0\n",
      "train_loss : 4.958388359455057e-07 val_loss : 0.10516411811113358\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 694/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0971199216669446e-06 val_loss : 0.10506809502840042\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 695/1000\n",
      "Steps: 0\n",
      "train_loss : 1.97238460373228e-06 val_loss : 0.10491499304771423\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 696/1000\n",
      "Steps: 0\n",
      "train_loss : 2.386037712653888e-06 val_loss : 0.10463441908359528\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 697/1000\n",
      "Steps: 0\n",
      "train_loss : 4.8613748191428385e-06 val_loss : 0.10434415936470032\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 698/1000\n",
      "Steps: 0\n",
      "train_loss : 7.391188148631044e-07 val_loss : 0.10406753420829773\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 699/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1623256028769902e-06 val_loss : 0.10304056107997894\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 700/1000\n",
      "Steps: 0\n",
      "train_loss : 6.046199700904253e-07 val_loss : 0.10266818851232529\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 701/1000\n",
      "Steps: 0\n",
      "train_loss : 2.7658380219008903e-06 val_loss : 0.10237912833690643\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 702/1000\n",
      "Steps: 0\n",
      "train_loss : 7.946317751361676e-07 val_loss : 0.10216324776411057\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 703/1000\n",
      "Steps: 0\n",
      "train_loss : 1.9022931866174985e-06 val_loss : 0.10244379192590714\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 704/1000\n",
      "Steps: 0\n",
      "train_loss : 3.1787180617470766e-06 val_loss : 0.10338503867387772\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 705/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8915364563554249e-06 val_loss : 0.10627945512533188\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 706/1000\n",
      "Steps: 0\n",
      "train_loss : 3.112015104989041e-06 val_loss : 0.10807611793279648\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 707/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6705638330449801e-06 val_loss : 0.10904348641633987\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 708/1000\n",
      "Steps: 0\n",
      "train_loss : 6.60131678387188e-07 val_loss : 0.10952642560005188\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 709/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1589544504886362e-05 val_loss : 0.1347513198852539\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 710/1000\n",
      "Steps: 0\n",
      "train_loss : 2.662527745656007e-06 val_loss : 0.1489887684583664\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 711/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4120853721522053e-05 val_loss : 0.15690425038337708\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 712/1000\n",
      "Steps: 0\n",
      "train_loss : 7.484286953740593e-07 val_loss : 0.16121885180473328\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 713/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0658576826472198e-06 val_loss : 0.163687065243721\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 714/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8526640733161913e-06 val_loss : 0.1648535430431366\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 715/1000\n",
      "Steps: 0\n",
      "train_loss : 2.3036952683241907e-06 val_loss : 0.165289044380188\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 716/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4950641030964108e-06 val_loss : 0.16545327007770538\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 717/1000\n",
      "Steps: 0\n",
      "train_loss : 3.86600244581814e-06 val_loss : 0.16538797318935394\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 718/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1568232924096264e-06 val_loss : 0.1652744710445404\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 719/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1832023879776444e-06 val_loss : 0.16330303251743317\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 720/1000\n",
      "Steps: 0\n",
      "train_loss : 9.056463767365131e-07 val_loss : 0.1610390692949295\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 721/1000\n",
      "Steps: 0\n",
      "train_loss : 8.043112188715895e-07 val_loss : 0.1595492660999298\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 722/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1512567727199894e-06 val_loss : 0.15854798257350922\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 723/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4562905398161094e-06 val_loss : 0.15768654644489288\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 724/1000\n",
      "Steps: 0\n",
      "train_loss : 9.63401484455062e-07 val_loss : 0.15696211159229279\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 725/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2223435668090588e-06 val_loss : 0.1563343107700348\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 726/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1321701521183058e-06 val_loss : 0.15587583184242249\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 727/1000\n",
      "Steps: 0\n",
      "train_loss : 5.3570141467673695e-06 val_loss : 0.15531955659389496\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 728/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2785998706021929e-06 val_loss : 0.1546187549829483\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 729/1000\n",
      "Steps: 0\n",
      "train_loss : 2.535201340947424e-06 val_loss : 0.1492524892091751\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 730/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0192376425143265e-06 val_loss : 0.13024142384529114\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 731/1000\n",
      "Steps: 0\n",
      "train_loss : 6.284715880156e-07 val_loss : 0.11844229698181152\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 732/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1470819316627967e-06 val_loss : 0.11125610023736954\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 733/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8829317610880026e-06 val_loss : 0.10702496767044067\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 734/1000\n",
      "Steps: 0\n",
      "train_loss : 3.895761268779552e-06 val_loss : 0.10493471473455429\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 735/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5667301031262466e-07 val_loss : 0.10391031205654144\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 736/1000\n",
      "Steps: 0\n",
      "train_loss : 9.362073313923247e-07 val_loss : 0.10314520448446274\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 737/1000\n",
      "Steps: 0\n",
      "train_loss : 7.579396678636385e-06 val_loss : 0.1025673896074295\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 738/1000\n",
      "Steps: 0\n",
      "train_loss : 1.443615190055425e-06 val_loss : 0.10206408053636551\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 739/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5759450008090425e-06 val_loss : 0.10182835161685944\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 740/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7730535716964369e-06 val_loss : 0.10160838812589645\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 741/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2495250217625652e-06 val_loss : 0.10141965746879578\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 742/1000\n",
      "Steps: 0\n",
      "train_loss : 8.408222299749468e-07 val_loss : 0.10132510215044022\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 743/1000\n",
      "Steps: 0\n",
      "train_loss : 1.267076763156183e-06 val_loss : 0.10121791064739227\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 744/1000\n",
      "Steps: 0\n",
      "train_loss : 2.148643119426197e-06 val_loss : 0.10102079063653946\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 745/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2805760778510375e-06 val_loss : 0.10076400637626648\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 746/1000\n",
      "Steps: 0\n",
      "train_loss : 8.542288355783967e-07 val_loss : 0.10058806836605072\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 747/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2793327769600183e-06 val_loss : 0.10026632249355316\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 748/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8133057665181695e-06 val_loss : 0.09954970329999924\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 749/1000\n",
      "Steps: 0\n",
      "train_loss : 6.694425081832378e-07 val_loss : 0.09906204044818878\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 750/1000\n",
      "Steps: 0\n",
      "train_loss : 5.90842446968054e-07 val_loss : 0.09876479208469391\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 751/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2670510756151998e-06 val_loss : 0.09856430441141129\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 752/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2700432080237078e-06 val_loss : 0.09836753457784653\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 753/1000\n",
      "Steps: 0\n",
      "train_loss : 9.257485515945518e-07 val_loss : 0.09789154678583145\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 754/1000\n",
      "Steps: 0\n",
      "train_loss : 6.433688128026915e-07 val_loss : 0.09748457372188568\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 755/1000\n",
      "Steps: 0\n",
      "train_loss : 5.566458634120864e-06 val_loss : 0.09081681817770004\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 756/1000\n",
      "Steps: 0\n",
      "train_loss : 3.788661700809826e-07 val_loss : 0.08669538050889969\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 757/1000\n",
      "Steps: 0\n",
      "train_loss : 5.245308230428236e-07 val_loss : 0.08421660959720612\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 758/1000\n",
      "Steps: 0\n",
      "train_loss : 2.851962526051466e-06 val_loss : 0.08282721787691116\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 759/1000\n",
      "Steps: 0\n",
      "train_loss : 7.644542719731362e-07 val_loss : 0.08221178501844406\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 760/1000\n",
      "Steps: 0\n",
      "train_loss : 5.707205389171577e-07 val_loss : 0.08188773691654205\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 761/1000\n",
      "Steps: 0\n",
      "train_loss : 2.704621194027368e-06 val_loss : 0.0817517638206482\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 762/1000\n",
      "Steps: 0\n",
      "train_loss : 9.95062626429899e-07 val_loss : 0.08160492777824402\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 763/1000\n",
      "Steps: 0\n",
      "train_loss : 3.479823766383561e-06 val_loss : 0.08148476481437683\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 764/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1180310401925908e-06 val_loss : 0.08112635463476181\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 765/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4175914941461088e-06 val_loss : 0.08081071823835373\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 766/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5364036514142754e-06 val_loss : 0.08063408732414246\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 767/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7481098424809715e-06 val_loss : 0.0807354524731636\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 768/1000\n",
      "Steps: 0\n",
      "train_loss : 9.94302325807439e-07 val_loss : 0.08075001835823059\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 769/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4209443804702459e-06 val_loss : 0.0806427001953125\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 770/1000\n",
      "Steps: 0\n",
      "train_loss : 8.598270994752966e-07 val_loss : 0.08050044625997543\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 771/1000\n",
      "Steps: 0\n",
      "train_loss : 9.172158399906038e-07 val_loss : 0.08033280074596405\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 772/1000\n",
      "Steps: 0\n",
      "train_loss : 3.098265602829997e-06 val_loss : 0.0801667794585228\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 773/1000\n",
      "Steps: 0\n",
      "train_loss : 4.373698999415865e-06 val_loss : 0.08001880347728729\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 774/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2528815389600823e-06 val_loss : 0.07982085645198822\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 775/1000\n",
      "Steps: 0\n",
      "train_loss : 3.2234275366249674e-06 val_loss : 0.07959751039743423\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 776/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7514592173029086e-06 val_loss : 0.07950637489557266\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 777/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0975174291161239e-06 val_loss : 0.07960911840200424\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 778/1000\n",
      "Steps: 0\n",
      "train_loss : 1.307241612380494e-06 val_loss : 0.08035136759281158\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 779/1000\n",
      "Steps: 0\n",
      "train_loss : 4.2915544611332735e-07 val_loss : 0.08247349411249161\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 780/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4872366108420464e-06 val_loss : 0.08385647088289261\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 781/1000\n",
      "Steps: 0\n",
      "train_loss : 2.275736548540408e-06 val_loss : 0.08444322645664215\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 782/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2260834672872533e-06 val_loss : 0.08469342440366745\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 783/1000\n",
      "Steps: 0\n",
      "train_loss : 9.119832938608852e-07 val_loss : 0.08469481021165848\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 784/1000\n",
      "Steps: 0\n",
      "train_loss : 5.555192502981754e-06 val_loss : 0.08451288193464279\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 785/1000\n",
      "Steps: 0\n",
      "train_loss : 3.1712548661744223e-06 val_loss : 0.08415286988019943\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 786/1000\n",
      "Steps: 0\n",
      "train_loss : 2.389773419508856e-06 val_loss : 0.08381733298301697\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 787/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8798689964683035e-06 val_loss : 0.09117688983678818\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 788/1000\n",
      "Steps: 0\n",
      "train_loss : 8.512624710022009e-07 val_loss : 0.09623408317565918\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 789/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3937225766369466e-06 val_loss : 0.09937691688537598\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 790/1000\n",
      "Steps: 0\n",
      "train_loss : 5.114947157380811e-07 val_loss : 0.10120458155870438\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 791/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5028362341240609e-06 val_loss : 0.1020708680152893\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 792/1000\n",
      "Steps: 0\n",
      "train_loss : 9.749577316142677e-07 val_loss : 0.1023234874010086\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 793/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4799749496651204e-06 val_loss : 0.10237924754619598\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 794/1000\n",
      "Steps: 0\n",
      "train_loss : 1.906466729906242e-06 val_loss : 0.10226058214902878\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 795/1000\n",
      "Steps: 0\n",
      "train_loss : 5.763146134540875e-07 val_loss : 0.1022198498249054\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 796/1000\n",
      "Steps: 0\n",
      "train_loss : 6.325710884880209e-07 val_loss : 0.10215778648853302\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 797/1000\n",
      "Steps: 0\n",
      "train_loss : 2.798248962676553e-06 val_loss : 0.10202547907829285\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 798/1000\n",
      "Steps: 0\n",
      "train_loss : 3.6582656690598017e-07 val_loss : 0.10193227231502533\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 799/1000\n",
      "Steps: 0\n",
      "train_loss : 2.220959926546584e-06 val_loss : 0.10175426304340363\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 800/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7328003139027714e-06 val_loss : 0.10124660283327103\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 801/1000\n",
      "Steps: 0\n",
      "train_loss : 8.467960753932857e-07 val_loss : 0.10034464299678802\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 802/1000\n",
      "Steps: 0\n",
      "train_loss : 4.824326282459879e-07 val_loss : 0.09983590990304947\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 803/1000\n",
      "Steps: 0\n",
      "train_loss : 6.69452217749722e-07 val_loss : 0.0994945615530014\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 804/1000\n",
      "Steps: 0\n",
      "train_loss : 6.437401538050836e-07 val_loss : 0.09924627840518951\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 805/1000\n",
      "Steps: 0\n",
      "train_loss : 8.199657173690866e-07 val_loss : 0.09894713759422302\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 806/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0144470579120934e-06 val_loss : 0.09873703867197037\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 807/1000\n",
      "Steps: 0\n",
      "train_loss : 3.758361469863303e-06 val_loss : 0.0984739363193512\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 808/1000\n",
      "Steps: 0\n",
      "train_loss : 5.3494367790563045e-06 val_loss : 0.09800738841295242\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 809/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4034367737281172e-06 val_loss : 0.09754066169261932\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 810/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2406152649191427e-06 val_loss : 0.09708915650844574\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 811/1000\n",
      "Steps: 0\n",
      "train_loss : 8.989459736596928e-07 val_loss : 0.09680386632680893\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 812/1000\n",
      "Steps: 0\n",
      "train_loss : 7.260824418153789e-07 val_loss : 0.0967581495642662\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 813/1000\n",
      "Steps: 0\n",
      "train_loss : 4.703623750401675e-06 val_loss : 0.09666503220796585\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 814/1000\n",
      "Steps: 0\n",
      "train_loss : 4.545585159831944e-06 val_loss : 0.09674343466758728\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 815/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0535651824739034e-06 val_loss : 0.0966496542096138\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 816/1000\n",
      "Steps: 0\n",
      "train_loss : 7.868067569916093e-07 val_loss : 0.0966285839676857\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 817/1000\n",
      "Steps: 0\n",
      "train_loss : 9.369604597964098e-07 val_loss : 0.09657078981399536\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 818/1000\n",
      "Steps: 0\n",
      "train_loss : 7.23462889595794e-07 val_loss : 0.09605249017477036\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 819/1000\n",
      "Steps: 0\n",
      "train_loss : 3.2111837498405295e-06 val_loss : 0.09563417732715607\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 820/1000\n",
      "Steps: 0\n",
      "train_loss : 8.859113023618192e-07 val_loss : 0.09474900364875793\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 821/1000\n",
      "Steps: 0\n",
      "train_loss : 4.041952536226745e-07 val_loss : 0.0938020795583725\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 822/1000\n",
      "Steps: 0\n",
      "train_loss : 6.549215051165902e-07 val_loss : 0.09306162595748901\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 823/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1910644658996717e-06 val_loss : 0.09259068220853806\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 824/1000\n",
      "Steps: 0\n",
      "train_loss : 3.080705354818747e-06 val_loss : 0.09213826060295105\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 825/1000\n",
      "Steps: 0\n",
      "train_loss : 5.80042397757552e-07 val_loss : 0.09181296080350876\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 826/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1541582665586247e-06 val_loss : 0.0916069969534874\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 827/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3117677298168928e-06 val_loss : 0.09162039309740067\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 828/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3173717320569268e-06 val_loss : 0.09133268147706985\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 829/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5021084013587824e-06 val_loss : 0.0710742324590683\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 830/1000\n",
      "Steps: 0\n",
      "train_loss : 8.628175052649567e-07 val_loss : 0.055730100721120834\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 831/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8099597511422872e-06 val_loss : 0.047112900763750076\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 832/1000\n",
      "Steps: 0\n",
      "train_loss : 5.055314346691376e-07 val_loss : 0.042235296219587326\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 833/1000\n",
      "Steps: 0\n",
      "train_loss : 7.793502135200469e-07 val_loss : 0.03957931324839592\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 834/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2219702202619374e-06 val_loss : 0.03930816799402237\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 835/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2634274962740618e-06 val_loss : 0.04009497910737991\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 836/1000\n",
      "Steps: 0\n",
      "train_loss : 6.418838268018589e-07 val_loss : 0.040571149438619614\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 837/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4026879007644765e-06 val_loss : 0.04091200605034828\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 838/1000\n",
      "Steps: 0\n",
      "train_loss : 2.053234022980632e-06 val_loss : 0.04111015796661377\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 839/1000\n",
      "Steps: 0\n",
      "train_loss : 9.440075984912256e-07 val_loss : 0.041042882949113846\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 840/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4779363425532211e-06 val_loss : 0.0406217947602272\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 841/1000\n",
      "Steps: 0\n",
      "train_loss : 4.379582227898026e-06 val_loss : 0.04526042193174362\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 842/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3493788628693437e-06 val_loss : 0.048364974558353424\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 843/1000\n",
      "Steps: 0\n",
      "train_loss : 4.440615569478723e-07 val_loss : 0.05027881637215614\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 844/1000\n",
      "Steps: 0\n",
      "train_loss : 5.744534519180888e-07 val_loss : 0.05139397457242012\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 845/1000\n",
      "Steps: 0\n",
      "train_loss : 5.889856900864743e-07 val_loss : 0.05214611068367958\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 846/1000\n",
      "Steps: 0\n",
      "train_loss : 8.385763663909529e-07 val_loss : 0.052508775144815445\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 847/1000\n",
      "Steps: 0\n",
      "train_loss : 1.699656476716882e-06 val_loss : 0.05238524451851845\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 848/1000\n",
      "Steps: 0\n",
      "train_loss : 4.977088714497313e-07 val_loss : 0.05230233818292618\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 849/1000\n",
      "Steps: 0\n",
      "train_loss : 4.043999165048717e-06 val_loss : 0.05238393694162369\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 850/1000\n",
      "Steps: 0\n",
      "train_loss : 6.86215363998599e-07 val_loss : 0.052227236330509186\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 851/1000\n",
      "Steps: 0\n",
      "train_loss : 8.233243832478365e-07 val_loss : 0.05203142389655113\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 852/1000\n",
      "Steps: 0\n",
      "train_loss : 3.576300493079998e-07 val_loss : 0.051945820450782776\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 853/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1672074819557566e-06 val_loss : 0.05174519494175911\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 854/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5913918520359404e-06 val_loss : 0.05138536915183067\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 855/1000\n",
      "Steps: 0\n",
      "train_loss : 2.000328167639509e-06 val_loss : 0.051118116825819016\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 856/1000\n",
      "Steps: 0\n",
      "train_loss : 5.371936879328132e-07 val_loss : 0.05086234584450722\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 857/1000\n",
      "Steps: 0\n",
      "train_loss : 9.745634628188782e-07 val_loss : 0.051167745143175125\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 858/1000\n",
      "Steps: 0\n",
      "train_loss : 6.243762051383328e-07 val_loss : 0.05174192041158676\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 859/1000\n",
      "Steps: 0\n",
      "train_loss : 7.61849128139147e-07 val_loss : 0.05204359069466591\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 860/1000\n",
      "Steps: 0\n",
      "train_loss : 7.10053025443358e-07 val_loss : 0.05224604904651642\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 861/1000\n",
      "Steps: 0\n",
      "train_loss : 7.074557174746587e-07 val_loss : 0.05237240716814995\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 862/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8621273824237506e-06 val_loss : 0.052376627922058105\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 863/1000\n",
      "Steps: 0\n",
      "train_loss : 6.947807150936569e-07 val_loss : 0.052245624363422394\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 864/1000\n",
      "Steps: 0\n",
      "train_loss : 9.380427428595794e-07 val_loss : 0.052136022597551346\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 865/1000\n",
      "Steps: 0\n",
      "train_loss : 3.5465129286649246e-07 val_loss : 0.05202803760766983\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 866/1000\n",
      "Steps: 0\n",
      "train_loss : 7.584806297700197e-07 val_loss : 0.051935214549303055\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 867/1000\n",
      "Steps: 0\n",
      "train_loss : 8.344894538936387e-07 val_loss : 0.05195142328739166\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 868/1000\n",
      "Steps: 0\n",
      "train_loss : 6.552943560222957e-07 val_loss : 0.051754314452409744\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 869/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1470908390265322e-06 val_loss : 0.05160416290163994\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 870/1000\n",
      "Steps: 0\n",
      "train_loss : 1.2350193244969888e-06 val_loss : 0.05157379433512688\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 871/1000\n",
      "Steps: 0\n",
      "train_loss : 6.854754204255187e-07 val_loss : 0.05154713988304138\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 872/1000\n",
      "Steps: 0\n",
      "train_loss : 4.906292801365452e-07 val_loss : 0.051201365888118744\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 873/1000\n",
      "Steps: 0\n",
      "train_loss : 5.401717373842984e-07 val_loss : 0.05100857838988304\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 874/1000\n",
      "Steps: 0\n",
      "train_loss : 6.206461620195114e-07 val_loss : 0.050998296588659286\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 875/1000\n",
      "Steps: 0\n",
      "train_loss : 7.625840268588035e-07 val_loss : 0.05099097639322281\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 876/1000\n",
      "Steps: 0\n",
      "train_loss : 4.593376687012096e-07 val_loss : 0.05094551667571068\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 877/1000\n",
      "Steps: 0\n",
      "train_loss : 7.156521476758826e-07 val_loss : 0.050891924649477005\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 878/1000\n",
      "Steps: 0\n",
      "train_loss : 8.911291317303949e-07 val_loss : 0.050821371376514435\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 879/1000\n",
      "Steps: 0\n",
      "train_loss : 7.03722284356445e-07 val_loss : 0.05080607533454895\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 880/1000\n",
      "Steps: 0\n",
      "train_loss : 2.656152275903878e-07 val_loss : 0.050989922136068344\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 881/1000\n",
      "Steps: 0\n",
      "train_loss : 7.391151740421265e-07 val_loss : 0.05099041014909744\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 882/1000\n",
      "Steps: 0\n",
      "train_loss : 2.0335577858077158e-06 val_loss : 0.05081093683838844\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 883/1000\n",
      "Steps: 0\n",
      "train_loss : 1.406748140198033e-06 val_loss : 0.05177823454141617\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 884/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0759399970083906e-06 val_loss : 0.05242421478033066\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 885/1000\n",
      "Steps: 0\n",
      "train_loss : 8.09898028819589e-07 val_loss : 0.05279121547937393\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 886/1000\n",
      "Steps: 0\n",
      "train_loss : 6.96648638154329e-07 val_loss : 0.05299028009176254\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 887/1000\n",
      "Steps: 0\n",
      "train_loss : 8.121453902276699e-07 val_loss : 0.05299753695726395\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 888/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6955747646818508e-06 val_loss : 0.05295253545045853\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 889/1000\n",
      "Steps: 0\n",
      "train_loss : 1.8949130534906545e-06 val_loss : 0.05281219258904457\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 890/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3337337847474373e-06 val_loss : 0.052493736147880554\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 891/1000\n",
      "Steps: 0\n",
      "train_loss : 4.097848602668819e-07 val_loss : 0.05215393006801605\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 892/1000\n",
      "Steps: 0\n",
      "train_loss : 6.933011704290948e-07 val_loss : 0.051992326974868774\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 893/1000\n",
      "Steps: 0\n",
      "train_loss : 1.248073857595955e-06 val_loss : 0.051919206976890564\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 894/1000\n",
      "Steps: 0\n",
      "train_loss : 1.881278166138145e-07 val_loss : 0.05183639004826546\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 895/1000\n",
      "Steps: 0\n",
      "train_loss : 1.843091968112276e-06 val_loss : 0.05156390741467476\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 896/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0219124007448954e-06 val_loss : 0.05122896656394005\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 897/1000\n",
      "Steps: 0\n",
      "train_loss : 4.690222354497564e-07 val_loss : 0.051002517342567444\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 898/1000\n",
      "Steps: 0\n",
      "train_loss : 8.66904638030519e-07 val_loss : 0.05189192295074463\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 899/1000\n",
      "Steps: 0\n",
      "train_loss : 6.888180422492951e-07 val_loss : 0.05249885097146034\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 900/1000\n",
      "Steps: 0\n",
      "train_loss : 7.506701919623993e-07 val_loss : 0.0528579019010067\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 901/1000\n",
      "Steps: 0\n",
      "train_loss : 4.958295582468963e-06 val_loss : 0.053110867738723755\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 902/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7585471375980433e-06 val_loss : 0.05318122357130051\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 903/1000\n",
      "Steps: 0\n",
      "train_loss : 4.380986240448692e-07 val_loss : 0.053077004849910736\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 904/1000\n",
      "Steps: 0\n",
      "train_loss : 1.4805685808028102e-06 val_loss : 0.05284067988395691\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 905/1000\n",
      "Steps: 0\n",
      "train_loss : 8.516281326365061e-07 val_loss : 0.05258118361234665\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 906/1000\n",
      "Steps: 0\n",
      "train_loss : 9.071506894997583e-07 val_loss : 0.052309922873973846\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 907/1000\n",
      "Steps: 0\n",
      "train_loss : 2.5252139721487765e-06 val_loss : 0.0521882139146328\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 908/1000\n",
      "Steps: 0\n",
      "train_loss : 3.434760117215774e-07 val_loss : 0.05206570774316788\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 909/1000\n",
      "Steps: 0\n",
      "train_loss : 6.105869331918257e-07 val_loss : 0.05234866216778755\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 910/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4831752913078164e-07 val_loss : 0.05251418426632881\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 911/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1098339577131354e-06 val_loss : 0.05249914154410362\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 912/1000\n",
      "Steps: 0\n",
      "train_loss : 4.260552321966315e-06 val_loss : 0.08610905706882477\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 913/1000\n",
      "Steps: 0\n",
      "train_loss : 4.3698143059600625e-07 val_loss : 0.10685914754867554\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 914/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4071161021765873e-06 val_loss : 0.1189904734492302\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 915/1000\n",
      "Steps: 0\n",
      "train_loss : 4.091968431652049e-06 val_loss : 0.12535782158374786\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 916/1000\n",
      "Steps: 0\n",
      "train_loss : 6.083584310090373e-07 val_loss : 0.12896741926670074\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 917/1000\n",
      "Steps: 0\n",
      "train_loss : 5.670050455819364e-07 val_loss : 0.13114169239997864\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 918/1000\n",
      "Steps: 0\n",
      "train_loss : 1.5729699889277526e-06 val_loss : 0.13230010867118835\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 919/1000\n",
      "Steps: 0\n",
      "train_loss : 3.0651134522940993e-06 val_loss : 0.13272275030612946\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 920/1000\n",
      "Steps: 0\n",
      "train_loss : 4.5523612897113707e-07 val_loss : 0.1328551173210144\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 921/1000\n",
      "Steps: 0\n",
      "train_loss : 3.4317731788746642e-06 val_loss : 0.1328553855419159\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 922/1000\n",
      "Steps: 0\n",
      "train_loss : 6.571596927074097e-07 val_loss : 0.13149520754814148\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 923/1000\n",
      "Steps: 0\n",
      "train_loss : 5.521015154386077e-07 val_loss : 0.13072256743907928\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 924/1000\n",
      "Steps: 0\n",
      "train_loss : 2.359973191801146e-06 val_loss : 0.1304272562265396\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 925/1000\n",
      "Steps: 0\n",
      "train_loss : 3.2652211647388183e-06 val_loss : 0.12989386916160583\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 926/1000\n",
      "Steps: 0\n",
      "train_loss : 7.342826108924783e-07 val_loss : 0.12936677038669586\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 927/1000\n",
      "Steps: 0\n",
      "train_loss : 4.146299886542693e-07 val_loss : 0.1289750337600708\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 928/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7114893083203242e-06 val_loss : 0.12854473292827606\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 929/1000\n",
      "Steps: 0\n",
      "train_loss : 2.559280204650349e-07 val_loss : 0.12773045897483826\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 930/1000\n",
      "Steps: 0\n",
      "train_loss : 9.466459054863207e-07 val_loss : 0.12713320553302765\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 931/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1415092501465552e-06 val_loss : 0.12679614126682281\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 932/1000\n",
      "Steps: 0\n",
      "train_loss : 8.206974548841117e-07 val_loss : 0.12623447179794312\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 933/1000\n",
      "Steps: 0\n",
      "train_loss : 1.0383066687325026e-06 val_loss : 0.12577512860298157\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 934/1000\n",
      "Steps: 0\n",
      "train_loss : 9.432945915932577e-07 val_loss : 0.12532053887844086\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 935/1000\n",
      "Steps: 0\n",
      "train_loss : 5.32731153413124e-07 val_loss : 0.12486030906438828\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 936/1000\n",
      "Steps: 0\n",
      "train_loss : 9.793962391313472e-07 val_loss : 0.12422849237918854\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 937/1000\n",
      "Steps: 0\n",
      "train_loss : 2.074555072795192e-06 val_loss : 0.12296155840158463\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 938/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2314534113831997e-07 val_loss : 0.12205707281827927\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 939/1000\n",
      "Steps: 0\n",
      "train_loss : 5.602986725250503e-07 val_loss : 0.12143923342227936\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 940/1000\n",
      "Steps: 0\n",
      "train_loss : 1.699302396218627e-06 val_loss : 0.12096289545297623\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 941/1000\n",
      "Steps: 0\n",
      "train_loss : 1.7447139370574405e-06 val_loss : 0.12105153501033783\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 942/1000\n",
      "Steps: 0\n",
      "train_loss : 2.8759324521843155e-07 val_loss : 0.12149576842784882\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 943/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2044106060548074e-06 val_loss : 0.12081950157880783\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 944/1000\n",
      "Steps: 0\n",
      "train_loss : 9.500085354829935e-07 val_loss : 0.12039752304553986\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 945/1000\n",
      "Steps: 0\n",
      "train_loss : 5.941957027744138e-07 val_loss : 0.11975295841693878\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 946/1000\n",
      "Steps: 0\n",
      "train_loss : 4.6567242435457955e-07 val_loss : 0.11933727562427521\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 947/1000\n",
      "Steps: 0\n",
      "train_loss : 3.2708262551750524e-07 val_loss : 0.1189516931772232\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 948/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3315244643763436e-06 val_loss : 0.11860953271389008\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 949/1000\n",
      "Steps: 0\n",
      "train_loss : 5.923363538329341e-07 val_loss : 0.11828739941120148\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 950/1000\n",
      "Steps: 0\n",
      "train_loss : 1.747363948823022e-06 val_loss : 0.11793848127126694\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 951/1000\n",
      "Steps: 0\n",
      "train_loss : 6.657213361904723e-07 val_loss : 0.11745818704366684\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 952/1000\n",
      "Steps: 0\n",
      "train_loss : 4.4667029754918983e-07 val_loss : 0.11698884516954422\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 953/1000\n",
      "Steps: 0\n",
      "train_loss : 6.687154431972431e-07 val_loss : 0.11654486507177353\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 954/1000\n",
      "Steps: 0\n",
      "train_loss : 1.1459596727547705e-06 val_loss : 0.11591103672981262\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 955/1000\n",
      "Steps: 0\n",
      "train_loss : 2.4102705538098234e-07 val_loss : 0.11531111598014832\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 956/1000\n",
      "Steps: 0\n",
      "train_loss : 3.500054971539157e-06 val_loss : 0.11455068737268448\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 957/1000\n",
      "Steps: 0\n",
      "train_loss : 6.437425923877526e-07 val_loss : 0.11541077494621277\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 958/1000\n",
      "Steps: 0\n",
      "train_loss : 4.213377863493406e-07 val_loss : 0.11754237860441208\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 959/1000\n",
      "Steps: 0\n",
      "train_loss : 1.6465816514710242e-07 val_loss : 0.11869865655899048\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 960/1000\n",
      "Steps: 0\n",
      "train_loss : 6.351732523057763e-07 val_loss : 0.11870218068361282\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 961/1000\n",
      "Steps: 0\n",
      "train_loss : 7.249650487040071e-07 val_loss : 0.11851418763399124\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 962/1000\n",
      "Steps: 0\n",
      "train_loss : 4.66412961941387e-07 val_loss : 0.11835192143917084\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 963/1000\n",
      "Steps: 0\n",
      "train_loss : 6.552957188432628e-07 val_loss : 0.1182527095079422\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 964/1000\n",
      "Steps: 0\n",
      "train_loss : 8.237032524505139e-07 val_loss : 0.11824575811624527\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 965/1000\n",
      "Steps: 0\n",
      "train_loss : 7.245977130310166e-07 val_loss : 0.11813799291849136\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 966/1000\n",
      "Steps: 0\n",
      "train_loss : 6.113319827250052e-07 val_loss : 0.1178494542837143\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 967/1000\n",
      "Steps: 0\n",
      "train_loss : 4.582194975455423e-07 val_loss : 0.11759629845619202\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 968/1000\n",
      "Steps: 0\n",
      "train_loss : 5.681180226702053e-07 val_loss : 0.11732970923185349\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 969/1000\n",
      "Steps: 0\n",
      "train_loss : 2.522050969844258e-07 val_loss : 0.11710933595895767\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 970/1000\n",
      "Steps: 0\n",
      "train_loss : 2.524846601659192e-06 val_loss : 0.11685851216316223\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 971/1000\n",
      "Steps: 0\n",
      "train_loss : 1.3792288498848392e-06 val_loss : 0.11636942625045776\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 972/1000\n",
      "Steps: 0\n",
      "train_loss : 4.3996520133759985e-07 val_loss : 0.11594592779874802\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 973/1000\n",
      "Steps: 0\n",
      "train_loss : 4.906300851814649e-07 val_loss : 0.11534050852060318\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 974/1000\n",
      "Steps: 0\n",
      "train_loss : 6.772691619971738e-07 val_loss : 0.11501394957304001\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 975/1000\n",
      "Steps: 0\n",
      "train_loss : 5.770521369186099e-07 val_loss : 0.11501253396272659\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 976/1000\n",
      "Steps: 0\n",
      "train_loss : 8.903670050131041e-07 val_loss : 0.11551428586244583\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 977/1000\n",
      "Steps: 0\n",
      "train_loss : 2.1867557222776668e-07 val_loss : 0.115742027759552\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 978/1000\n",
      "Steps: 0\n",
      "train_loss : 9.093774181678782e-07 val_loss : 0.11563310772180557\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 979/1000\n",
      "Steps: 0\n",
      "train_loss : 2.2649916004979785e-07 val_loss : 0.11543666571378708\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 980/1000\n",
      "Steps: 0\n",
      "train_loss : 6.511912467033198e-07 val_loss : 0.11524073779582977\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 981/1000\n",
      "Steps: 0\n",
      "train_loss : 9.034274398800335e-07 val_loss : 0.11517282575368881\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 982/1000\n",
      "Steps: 0\n",
      "train_loss : 3.87060399020811e-07 val_loss : 0.11468271911144257\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 983/1000\n",
      "Steps: 0\n",
      "train_loss : 6.061233296605905e-07 val_loss : 0.11380413174629211\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 984/1000\n",
      "Steps: 0\n",
      "train_loss : 3.356507633611727e-07 val_loss : 0.11333376169204712\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 985/1000\n",
      "Steps: 0\n",
      "train_loss : 6.020172666154622e-07 val_loss : 0.1130337044596672\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 986/1000\n",
      "Steps: 0\n",
      "train_loss : 4.202174665124403e-07 val_loss : 0.11278938502073288\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 987/1000\n",
      "Steps: 0\n",
      "train_loss : 3.803589763151649e-07 val_loss : 0.11251439899206161\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 988/1000\n",
      "Steps: 0\n",
      "train_loss : 1.327404386586295e-06 val_loss : 0.1124902069568634\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 989/1000\n",
      "Steps: 0\n",
      "train_loss : 3.7179044056756536e-07 val_loss : 0.11310126632452011\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 990/1000\n",
      "Steps: 0\n",
      "train_loss : 3.0249503755186426e-07 val_loss : 0.11326514184474945\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 991/1000\n",
      "Steps: 0\n",
      "train_loss : 6.906893446512185e-07 val_loss : 0.11311282217502594\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 992/1000\n",
      "Steps: 0\n",
      "train_loss : 6.236358530031793e-07 val_loss : 0.11301858723163605\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 993/1000\n",
      "Steps: 0\n",
      "train_loss : 6.616306905016244e-07 val_loss : 0.1129111647605896\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 994/1000\n",
      "Steps: 0\n",
      "train_loss : 5.554570606136621e-07 val_loss : 0.11272567510604858\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 995/1000\n",
      "Steps: 0\n",
      "train_loss : 6.437497837907813e-07 val_loss : 0.112517349421978\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 996/1000\n",
      "Steps: 0\n",
      "train_loss : 3.427295233393579e-07 val_loss : 0.11225944012403488\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 997/1000\n",
      "Steps: 0\n",
      "train_loss : 3.762584526612045e-07 val_loss : 0.11201432347297668\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 998/1000\n",
      "Steps: 0\n",
      "train_loss : 5.722210147496299e-07 val_loss : 0.11188871413469315\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 999/1000\n",
      "Steps: 0\n",
      "train_loss : 5.513572119753008e-07 val_loss : 0.11179379373788834\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 32\n",
      "batch accuracy: 16\n",
      "Epoch: 1000/1000\n",
      "Steps: 0\n",
      "train_loss : 4.7237495692797893e-07 val_loss : 0.11169088631868362\n",
      "train_accuracy : 100.0 val_accuracy : 96.7741935483871\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "clip = 5\n",
    "print_every = 40\n",
    "steps = 0\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc, epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    val_losses = []\n",
    "    train_accuracy = 0.0\n",
    "    val_accuracy = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        batch_size = inputs.size(0)  \n",
    "        h = model.init_hidden(batch_size)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        h = tuple([each.data for each in h])\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        if torch.isnan(loss):\n",
    "            logging.warning('NAN detected in training loss')\n",
    "            continue \n",
    "\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "        print(f'batch accuracy: {accuracy(output, labels)}')\n",
    "        \n",
    "        train_accuracy += accuracy(output, labels)\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    for inp, lab in val_loader:\n",
    "        val_h = model.init_hidden(inp.size(0))\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "        inp, lab = inp.to(device), lab.to(device)\n",
    "        out, val_h = model(inp, val_h)\n",
    "        val_loss = criterion(out.squeeze(), lab.float())\n",
    "        \n",
    "        if torch.isnan(val_loss):\n",
    "            logging.warning('NAN detected in validation loss')\n",
    "            continue\n",
    "\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracy += accuracy(out, lab)\n",
    "\n",
    "    epoch_train_loss = np.mean(train_loss)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_accuracy/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_accuracy/len(val_loader.dataset)\n",
    "    \n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "\n",
    "    # Logging to file\n",
    "    logging.info(f'Epoch: {epoch + 1}/{epochs}')\n",
    "    logging.info(f'train loss: {epoch_train_loss}, validation Loss: {epoch_val_loss}')\n",
    "    logging.info(f'training accuracy: {epoch_train_acc * 100}%, validation Accuracy: {epoch_val_acc * 100}%')\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}\")\n",
    "    print(f\"Steps: {steps}\")\n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    \n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '2024_01_23_poa_servicemodel.pt')\n",
    "        logging.info(\n",
    "            f\"vlidation loss decreased ({valid_loss_min:.6f} --> {epoch_val_loss:.6f}). saving model.\"\n",
    "            )\n",
    "        valid_loss_min = epoch_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value (raw): 0.73105788230896\n",
      "Predicted label: Power of Attorney Document\n"
     ]
    }
   ],
   "source": [
    "def predict(text, model, device):\n",
    "    vector = get_document_vector(text)\n",
    "    tensor = torch.tensor([vector], dtype=torch.float32).to(device)\n",
    "    \n",
    "    h = model.init_hidden(1)\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(tensor, h)\n",
    "        prediction = torch.sigmoid(output)\n",
    "        pred_label = (prediction >= 0.5).int()\n",
    "    \n",
    "    return prediction.item(), pred_label.item()\n",
    "\n",
    "sample_text = \" \\\n",
    "dokumente nurodytas mano asmens dokumentas yra tikras, originalas, galiojantis\\\n",
    "      ir priklausantis man, (V)\\nnuotoliniu bdu man notaras aikiai iaikino io\\\n",
    "          notarinio veiksmo prasm ir pasekmes, kurios man yra\\nvisikai suprantamos,\\\n",
    "              (vi)  dokument gavau i anksto ir turjau pakankamai laiko su juo \\\n",
    "                susipainti ir j\\nsuprasti, pateikti savo pasilymus ir pastabas \\\n",
    "\"\n",
    "model.to(device)\n",
    "pred, pred_label = predict(sample_text, model, device)\n",
    "print(f\"Predicted value (raw): {pred}\")\n",
    "print(f\"Predicted label: {('Other Document' if pred_label == 0 else 'Power of Attorney Document')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
